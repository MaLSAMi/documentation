{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MaLSAMi project documentation \u00b6 Welcome to the MaLSAMi project documentation. In here we will document our progress and almost all subprojects or programs we will create or write. If you want to take a deeper look in our open source code projects please refer to the MaLSAMi Github Page About the project \u00b6 You can find a general description of the project MaLSAMi in the About Section Prerequisite \u00b6 To contribute to this documentation please download the source code from the MaLSAMi Documentation Repository and follow the instructions at MkDocs . Documentation structure \u00b6 The documentation is structured into different subpages which are representing subprojects of the project MaLSAMi. Nevertheless also analysis results or specifications of the projects can be described in a subpage. Commands \u00b6 To work with MkDocs after installing it, you can use these commands mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. To upload the documentation to the git repository please following command, but be aware that changes might be immediately visible. mkdocs gh-deploy - Uploads build documentation sites to gh-pages branch Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#malsami-project-documentation","text":"Welcome to the MaLSAMi project documentation. In here we will document our progress and almost all subprojects or programs we will create or write. If you want to take a deeper look in our open source code projects please refer to the MaLSAMi Github Page","title":"MaLSAMi project documentation"},{"location":"#about-the-project","text":"You can find a general description of the project MaLSAMi in the About Section","title":"About the project"},{"location":"#prerequisite","text":"To contribute to this documentation please download the source code from the MaLSAMi Documentation Repository and follow the instructions at MkDocs .","title":"Prerequisite"},{"location":"#documentation-structure","text":"The documentation is structured into different subpages which are representing subprojects of the project MaLSAMi. Nevertheless also analysis results or specifications of the projects can be described in a subpage.","title":"Documentation structure"},{"location":"#commands","text":"To work with MkDocs after installing it, you can use these commands mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. To upload the documentation to the git repository please following command, but be aware that changes might be immediately visible. mkdocs gh-deploy - Uploads build documentation sites to gh-pages branch","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"about/","text":"Goal of the project \u00b6 This project is about schedulability analysis.","title":"About"},{"location":"about/#goal-of-the-project","text":"This project is about schedulability analysis.","title":"Goal of the project"},{"location":"concept/","text":"MaLSAMi project concept \u00b6 As the MaLSAMi project wants to train machine learning algorithms for schedulability analysis, it needs task data to do so. This task data is (in the scope of the project) artifical, which means it is generated from artifical tasks that execute arbitrary operations. These tasks are first generated within tasksets and then distributed to either KVM/QEMU driven virtual machines, to real hardware or to ARM Servers where the system is virtualized. basic concept of a task \u00b6 task parameters and strucutre \u00b6 basic concept of a taskset \u00b6 taskset parameters and structure \u00b6 distribution \u00b6 evaluation \u00b6","title":"Concept"},{"location":"concept/#malsami-project-concept","text":"As the MaLSAMi project wants to train machine learning algorithms for schedulability analysis, it needs task data to do so. This task data is (in the scope of the project) artifical, which means it is generated from artifical tasks that execute arbitrary operations. These tasks are first generated within tasksets and then distributed to either KVM/QEMU driven virtual machines, to real hardware or to ARM Servers where the system is virtualized.","title":"MaLSAMi project concept"},{"location":"concept/#basic-concept-of-a-task","text":"","title":"basic concept of a task"},{"location":"concept/#task-parameters-and-strucutre","text":"","title":"task parameters and strucutre"},{"location":"concept/#basic-concept-of-a-taskset","text":"","title":"basic concept of a taskset"},{"location":"concept/#taskset-parameters-and-structure","text":"","title":"taskset parameters and structure"},{"location":"concept/#distribution","text":"","title":"distribution"},{"location":"concept/#evaluation","text":"","title":"evaluation"},{"location":"testbed/","text":"MaLSAMi project testbed \u00b6 The MaLSAMi project testbed consists basically two parts. The data generation and task evaluation part and the test case setup, which is further divided. The first part, data generation and task evaluation is well described in the MaLSAMi concept . The second part, the test case setup is mainly copied from the Argos Research project](https://argos-research.github.io/documentation/) and further fitted to the projects needs. general scenario \u00b6 used ML algorithms \u00b6 offline ACC scenario \u00b6 online ACC scenario \u00b6 offline parking scenario \u00b6 online parking scenario \u00b6 evaluation \u00b6","title":"Testbed"},{"location":"testbed/#malsami-project-testbed","text":"The MaLSAMi project testbed consists basically two parts. The data generation and task evaluation part and the test case setup, which is further divided. The first part, data generation and task evaluation is well described in the MaLSAMi concept . The second part, the test case setup is mainly copied from the Argos Research project](https://argos-research.github.io/documentation/) and further fitted to the projects needs.","title":"MaLSAMi project testbed"},{"location":"testbed/#general-scenario","text":"","title":"general scenario"},{"location":"testbed/#used-ml-algorithms","text":"","title":"used ML algorithms"},{"location":"testbed/#offline-acc-scenario","text":"","title":"offline ACC scenario"},{"location":"testbed/#online-acc-scenario","text":"","title":"online ACC scenario"},{"location":"testbed/#offline-parking-scenario","text":"","title":"offline parking scenario"},{"location":"testbed/#online-parking-scenario","text":"","title":"online parking scenario"},{"location":"testbed/#evaluation","text":"","title":"evaluation"},{"location":"analysis/requirements-analysis/","text":"Requirements Analysis for MaLSAMi (Machine Learning based Schedulability Analysis for inter device Migration of software based components during Runtime) \u00b6 Overview \u00b6 Tasks are running on multiple electronic computing units (ECU). These ECUs periodically create checkpoints of the current state and progress of the running tasks. At some point in time, an ECU might fail. From the checkpoints and the information of the running tasks, the ECU must make a decision for migration of tasks on a failed ECU. This project hopes to utilize schedulability analysis to make better decisions on the migration of these components. After the ECU makes its decision, it must restore the checkpoint on another ECU and have that ECU execute the remaining tasks. The migration of a task by restoring a checkpoint to another ECU could happen either directly to another ECU or by collecting all the checkpoints of all the ECUs to a different machine and redistributing them to a chosen target ECU when necessary. Another variant of checkpointing would be to create an initial full checkpoint followed by smaller change-based incremental checkpoints. These incremental checkpoints might be integrated into the full checkpoint on the same ECU before sending it to another machine, or every checkpoint is sent right after creation. These smaller based checkpoints are motivated by the necessity of storing and retaining information in the event of an imminent failure. Furthermore, the data would prove to be useful for later analysis. Another possible use-case for checkpoints, which is not being looked into is the restart of failed tasks at its last known state on the same machine. The decision of where a task is migrated to is generally based on the information about the task. It could also be a posibillity to include the information gained through the checkpoints to find the best solution. We have chosen to employ machine learning to improve our ability to make these decisions. There are three general phases in which learning would be best applied: Offline Learning Heavyweight phase where there is a lot of data available and enough resources to extensively train the model. We can train on previously sampled data and can utilize our resources for complicated algorithms. This will be done on a different ECU or computer to analyze as much data as possible and to perform migration planning. Online Learning This type of online learning will be performed on very strong ECUs. Although these ECUs are strong, we do not have access to the entire dataset and all the resources as we are in the offline learning. Furthermore, we will be learning on data in real-time and will not be able to analyze both ends of the dataset. However, this aspect is necessary as it will simulate the migration planning in real time. These decisions will most likely have a greateer influence on the migration planning. online on normal ECUs (embedded boards) This is similiar to the online learning phase described before. The only difference is that the ECU will not be as powerful and may require even lighter weight algorithms. What we have \u00b6 Hardware Available \u00b6 3 Workstations: - titan V 3x gtx1080ti 2x tesla k20c quadro k4200 Data \u00b6 Checkpointing currently includes only the information in the memory. Checkpointing the capabilities or the registers is not possible yet. No data yet, we will have to generate it using the implemented distributor. Which data can be aquired from the distributor is dependent on the defined monitor, but the most information that can be gained are the parameters of each taskset, which were handed over to the genode operating system, and also the start and stop times of each job of each task and also the exit value. Available Software \u00b6 Python 3.5.2 Pytorch va Cuda v Qemu Genode cxxnet Theano Torch7 What we can do \u00b6 Multiple frameworks for deep learning and parallel programming. Pytorch allows easy high level implementation of deep neural networks along with GPU accelerated computation. This will be especially useful in accelerating computation of deep neural networks. These GPUs will allow the networks to train on more data in less time. This feature will be especially useful when during the offline training phase where we can train deep and expansive nueral networks with full use of resources. There are numerous other frameworks that can also be utilized. Pytorch is good because of its ease in utilizing GPU architecture with neural networks. However, there are numerous other libraries that are specialized to the type of network or learning technique we are using. Cuda-convnet is another project that utilizes C++ Cuda implementatoin of neural networks. If we observe that the neural networks are performing well and we want to optimize, we can then pursue these libraries. Shallow Learning techniques are much simpler than Deep Learning techniques and do not always require very sophisticated libraries or hardware. Furthermore, whether or not the learning phase can or should be parallelized can be decided later. Given the resources, we have for the offline training phase, we will attempt to parallelize and optimize the algorithms wherever possible. After these rudimentary shallow and deep learning techniques are applied. We can look into reinforcement learning, a newer machine learning approach that is especially used for autonomous driving. The main difference between reinforcement learning and regular supervised/unsupervised machine learning is how an agent decides which actions to take based on the environment. We are currently mostly concerned with schedulablitity analysis, which will be learned based on the data itself. However, further analysis of the acquired data and the patterns analyzed may bring some interest into this type of approach. Other preprocessing and/or unsupervised learning techniques can be implemented to enhance the analysis. This will all depend on the data and the patterns that emerge when it is sampled. The ECUs allow us to use multiple forms of information which will be helpful for machine learning training such as lidar, radars, etc. Checkpointing \u00b6 Current state and snapshot of resources could be used for restarting in case of ECU failure or other problems. Learning can be done by continually monitoring these states and then using them as inputs into the machine learning models. Deep Learning would react better to this as it would be able to properly account for different kinds of input better than shallow learning techniques. Furthermore, the more sophisticated/complicated the data, the more likely that deep learning will perform better. Reinforcement Learning would be helpful in the checkpointing as it will be able to decide whether or not it wants to add a checkpoint based on its environment and available states. Obviously, if the probability of an ecu failing in a particular environment is high, it would be a good idea to add a checkpoint. These are areas that reinforcement learning would be better able to handle rather than regular shallow/deep learning. Learning \u00b6 When it comes to learning techniques, there are many options. MaLSAMi is going to look into Deep and Shallow Learning based data analysis and decision making. Deep Learning \u00b6 Deep Learning works best when there is a lot of data to sample from. These algorithms will be mostly utilized in the \u2018offline\u2019 phase of the learning. Deep Learning has a variety of different neural network models such as Generative Adversarial Networks (GAN), Spiking Neural Networks (SNN), Feed Forward Networks (FNN), Recurrent Neural Networks (RNN) and Convolutional CNN. These networks are specializied for specific types of data mining and analysis and are never a \u2018one fits all\u2019 model. Therefore, we plan to analyze several of these different models. Each of the networks listed below are catered to a certain kind of problem, but they are not too specialized to be unadaptable. Shallow Learning \u00b6 Shallow Learning techniques are usually much simpler than deep learning. These require less time and energy to train and classify. However, as they are simpler, they do not have the same adaptibility of the neural networks. However, certain algorithms (Support Vector Machines and Random Forest) have proven to be quite effective in binary classifiaction. The aim of the shallow learning is to do an expansive test of different algorithms and understand what their fitting on the data indicates. High accuracy on certain algorithms will indicate different trends in the data. Regardless of whether or not shallow learning is used, these algorithms will bring more insight into the modelling of the data. Testing \u00b6 For both approaches, we will use the standard metrics of testing for shallow and deep learning. This will include shuffling of training splits, cross validation, and in depth classification reports measuring the accuracy, precision, and recall. The challenges with data mining is dealing with improper and unclean data. Optimally, we would have enough data for extensive testing. Hopefully, the distributor will be able to generate enough worthwhile data to train on.","title":"Requirements Analysis"},{"location":"analysis/requirements-analysis/#requirements-analysis-for-malsami-machine-learning-based-schedulability-analysis-for-inter-device-migration-of-software-based-components-during-runtime","text":"","title":"Requirements Analysis for MaLSAMi (Machine Learning based Schedulability Analysis for inter device Migration of software based components during Runtime)"},{"location":"analysis/requirements-analysis/#overview","text":"Tasks are running on multiple electronic computing units (ECU). These ECUs periodically create checkpoints of the current state and progress of the running tasks. At some point in time, an ECU might fail. From the checkpoints and the information of the running tasks, the ECU must make a decision for migration of tasks on a failed ECU. This project hopes to utilize schedulability analysis to make better decisions on the migration of these components. After the ECU makes its decision, it must restore the checkpoint on another ECU and have that ECU execute the remaining tasks. The migration of a task by restoring a checkpoint to another ECU could happen either directly to another ECU or by collecting all the checkpoints of all the ECUs to a different machine and redistributing them to a chosen target ECU when necessary. Another variant of checkpointing would be to create an initial full checkpoint followed by smaller change-based incremental checkpoints. These incremental checkpoints might be integrated into the full checkpoint on the same ECU before sending it to another machine, or every checkpoint is sent right after creation. These smaller based checkpoints are motivated by the necessity of storing and retaining information in the event of an imminent failure. Furthermore, the data would prove to be useful for later analysis. Another possible use-case for checkpoints, which is not being looked into is the restart of failed tasks at its last known state on the same machine. The decision of where a task is migrated to is generally based on the information about the task. It could also be a posibillity to include the information gained through the checkpoints to find the best solution. We have chosen to employ machine learning to improve our ability to make these decisions. There are three general phases in which learning would be best applied: Offline Learning Heavyweight phase where there is a lot of data available and enough resources to extensively train the model. We can train on previously sampled data and can utilize our resources for complicated algorithms. This will be done on a different ECU or computer to analyze as much data as possible and to perform migration planning. Online Learning This type of online learning will be performed on very strong ECUs. Although these ECUs are strong, we do not have access to the entire dataset and all the resources as we are in the offline learning. Furthermore, we will be learning on data in real-time and will not be able to analyze both ends of the dataset. However, this aspect is necessary as it will simulate the migration planning in real time. These decisions will most likely have a greateer influence on the migration planning. online on normal ECUs (embedded boards) This is similiar to the online learning phase described before. The only difference is that the ECU will not be as powerful and may require even lighter weight algorithms.","title":"Overview"},{"location":"analysis/requirements-analysis/#what-we-have","text":"","title":"What we have"},{"location":"analysis/requirements-analysis/#hardware-available","text":"3 Workstations: - titan V 3x gtx1080ti 2x tesla k20c quadro k4200","title":"Hardware Available"},{"location":"analysis/requirements-analysis/#data","text":"Checkpointing currently includes only the information in the memory. Checkpointing the capabilities or the registers is not possible yet. No data yet, we will have to generate it using the implemented distributor. Which data can be aquired from the distributor is dependent on the defined monitor, but the most information that can be gained are the parameters of each taskset, which were handed over to the genode operating system, and also the start and stop times of each job of each task and also the exit value.","title":"Data"},{"location":"analysis/requirements-analysis/#available-software","text":"Python 3.5.2 Pytorch va Cuda v Qemu Genode cxxnet Theano Torch7","title":"Available Software"},{"location":"analysis/requirements-analysis/#what-we-can-do","text":"Multiple frameworks for deep learning and parallel programming. Pytorch allows easy high level implementation of deep neural networks along with GPU accelerated computation. This will be especially useful in accelerating computation of deep neural networks. These GPUs will allow the networks to train on more data in less time. This feature will be especially useful when during the offline training phase where we can train deep and expansive nueral networks with full use of resources. There are numerous other frameworks that can also be utilized. Pytorch is good because of its ease in utilizing GPU architecture with neural networks. However, there are numerous other libraries that are specialized to the type of network or learning technique we are using. Cuda-convnet is another project that utilizes C++ Cuda implementatoin of neural networks. If we observe that the neural networks are performing well and we want to optimize, we can then pursue these libraries. Shallow Learning techniques are much simpler than Deep Learning techniques and do not always require very sophisticated libraries or hardware. Furthermore, whether or not the learning phase can or should be parallelized can be decided later. Given the resources, we have for the offline training phase, we will attempt to parallelize and optimize the algorithms wherever possible. After these rudimentary shallow and deep learning techniques are applied. We can look into reinforcement learning, a newer machine learning approach that is especially used for autonomous driving. The main difference between reinforcement learning and regular supervised/unsupervised machine learning is how an agent decides which actions to take based on the environment. We are currently mostly concerned with schedulablitity analysis, which will be learned based on the data itself. However, further analysis of the acquired data and the patterns analyzed may bring some interest into this type of approach. Other preprocessing and/or unsupervised learning techniques can be implemented to enhance the analysis. This will all depend on the data and the patterns that emerge when it is sampled. The ECUs allow us to use multiple forms of information which will be helpful for machine learning training such as lidar, radars, etc.","title":"What we can do"},{"location":"analysis/requirements-analysis/#checkpointing","text":"Current state and snapshot of resources could be used for restarting in case of ECU failure or other problems. Learning can be done by continually monitoring these states and then using them as inputs into the machine learning models. Deep Learning would react better to this as it would be able to properly account for different kinds of input better than shallow learning techniques. Furthermore, the more sophisticated/complicated the data, the more likely that deep learning will perform better. Reinforcement Learning would be helpful in the checkpointing as it will be able to decide whether or not it wants to add a checkpoint based on its environment and available states. Obviously, if the probability of an ecu failing in a particular environment is high, it would be a good idea to add a checkpoint. These are areas that reinforcement learning would be better able to handle rather than regular shallow/deep learning.","title":"Checkpointing"},{"location":"analysis/requirements-analysis/#learning","text":"When it comes to learning techniques, there are many options. MaLSAMi is going to look into Deep and Shallow Learning based data analysis and decision making.","title":"Learning"},{"location":"analysis/requirements-analysis/#deep-learning","text":"Deep Learning works best when there is a lot of data to sample from. These algorithms will be mostly utilized in the \u2018offline\u2019 phase of the learning. Deep Learning has a variety of different neural network models such as Generative Adversarial Networks (GAN), Spiking Neural Networks (SNN), Feed Forward Networks (FNN), Recurrent Neural Networks (RNN) and Convolutional CNN. These networks are specializied for specific types of data mining and analysis and are never a \u2018one fits all\u2019 model. Therefore, we plan to analyze several of these different models. Each of the networks listed below are catered to a certain kind of problem, but they are not too specialized to be unadaptable.","title":"Deep Learning"},{"location":"analysis/requirements-analysis/#shallow-learning","text":"Shallow Learning techniques are usually much simpler than deep learning. These require less time and energy to train and classify. However, as they are simpler, they do not have the same adaptibility of the neural networks. However, certain algorithms (Support Vector Machines and Random Forest) have proven to be quite effective in binary classifiaction. The aim of the shallow learning is to do an expansive test of different algorithms and understand what their fitting on the data indicates. High accuracy on certain algorithms will indicate different trends in the data. Regardless of whether or not shallow learning is used, these algorithms will bring more insight into the modelling of the data.","title":"Shallow Learning"},{"location":"analysis/requirements-analysis/#testing","text":"For both approaches, we will use the standard metrics of testing for shallow and deep learning. This will include shuffling of training splits, cross validation, and in depth classification reports measuring the accuracy, precision, and recall. The challenges with data mining is dealing with improper and unclean data. Optimally, we would have enough data for extensive testing. Hopefully, the distributor will be able to generate enough worthwhile data to train on.","title":"Testing"},{"location":"analysis/schedulability-analysis/","text":"Schedulability Analysis On real-time systems, tasks will be executed and processed on multiple different ECUs. These ECUs are responsible for various distributed tasks whose analysis is important for migration planning in the probable event of system failure. Schedulabilit analysis is one of the studies that aims to determine information about how these ECUs are planning tasks. With this information, the behaviors can be modified. On these multi-ecu systems, the ECUs hold information about the task such as the start/end time. In the event of an ECU failure, it must have a prevention/recovery method in which it can migrate unfinished tasks to other ECUs that it has not been able to complete. Our goal with schedulability analysis is to garner all the information from past, present, and future events for better damage control and migration planning. Checkpoints are also an important aspect of schedulability analysis. Generally, checkpointing include storing the current state of the machine and/or the task state for postponed execution. These checkpoints could include the memory, the assigned capabilities or the registers. Beside full checkpoints, incremental minor checkpointing could be useful as well. This would include small backups to ensure that no data is lost as a failure of a system can happen at an inconveninet time. The migration of a task by restoring a checkpoint to another ECU could happen either directly to another ECU or by collecting all the checkpoints of all the ECUs to a different machine and redistributing them to a chosen target ECU when necessary.Another variant of checkpointing would be to create an initial full checkpoint followed by smaller change-based incremental checkpoints. These incremental checkpoints might be integrated into the full checkpoint on the same ECU before sending it to another machine, or every checkpoint is sent right after creation. A possible use-case for checkpoints, which is not being looked into is the restart of failed tasks at its last known state on the same machine. The decision where a task is migrated to is mainly based on the general information about the task but it could also be a posibillity to include the information gained through the checkpoints to find the best solution. Learning (of any kind) can be performed in three general categories: -offline on a different ECU or computer for exactly the purpose of analysing the data and performing the migration planning. -online on very strong ECUs which are performing tasks and also the data analysis and decision making necessary for migration -online on normal ECUs (embedded boards) which are performing tasks and also the data analysis and decision making necessary for migration The advantage of offline learning is that we are able to utilize virtually all of our resources and compute time to test multiple algorithms to fit the data. The disadvantage with this is that we will be dealing with a static datasets. Althought this does not imply that the dataset is erroneous, it is not akin to real time data that will happen at the online phase. Furthremore, heavy computation and time used to fit a static datasets very likely leads to overfitting. Even if appropriate measures are made, it is possible that the online data could be different from that of the dataset used. Analogously, the online training is beneficial and detrimental for the opposite reasons. While online, we do not have as much time and resources as we do while offline. Especially in the situation that we are in now, we must process the data quickly. Therefore, we used the online training as more of a \u2018validation\u2019 stage in which we fine tune the models and hyperparameters. The distributor is the module responsible for data generation that we will be used for the schedulability analysis. See the distributor file for more information about the distributor. To further analyze the methods we are using, view Machine Learning and the requirement analysis","title":"Schedulability Analysis"},{"location":"data-generation/distributor/","text":"Distributor \u00b6 Distributor is the main class/entity that controls and distributes host sessions to manage tasksets. Upon startup, the distributor will have a preset value of one host session that it will be able to spawn. The user is permitted to change this number at any time up to a hardcoded limit of forty one. Machines set to be closed will finish their assigned taskset before being shut down. The distributor is mainly used for gathering large-scale data about autonomous system schedulability-tasks, which can be used for data mining and analysis. Set up and Configuration \u00b6 Clone the client-tools repository and initialize the submodules and place a working image.elf file inside the client-tools directory. With Vagrant \u00b6 A vagrant script is provided in the client-tools repository, which will set up the appropriate development environment and prepare it for use without any manual installation or configuration. (Executing the distributor inside a vagrant machine leads to an unknown error, which stops the execution at some point after about ten to thirty hours. As the vagrant machine serves only as a test and development environment, this is not a critical issue and will not be further investigated, as mentioned in the according issue ) Manual Setup \u00b6 Install Python 3.5 and pip3 sudo apt-get install python3.5 -qq sudo apt-get install python3-pip -qq Install the requirements for the taskgen module sudo pip3 install -r client-tools/taskgen/requirements.txt Install bridge functionality for networking: sudo apt-get install bridge-utils -qq Download DHCP service and move provided configuration file. sudo apt-get install isc-dhcp-server -qq sudo cp dhcpd.conf /etc/dhcp/ Set up the bridge and assign an IP address (consult the dhcp.conf file for more information on IP ranges) sudo brctl addbr br0 sudo ip addr add 10.200.40.1/21 dev br0 Adjust /etc/network/interfaces file with preliminary networking information sudo sh -c 'echo \"auto br0\\niface br0 inet dhcp\\nbridge_ports eth0\\nbridge_stp off\\nbridge_maxwait 0\\nbridge_fd 0\\n\" >> /etc/network/interfaces' Install qemu and screen for spawning host sessions from the distributor and for easy visualization of spawned sessions. sudo apt-get install qemu -qq sudo apt-get install screen -qq Start the dhcp service sudo systemctl start isc-dhcp-server The machine should now be ready for use. Using the Distributor \u00b6 The following is an example execution to provide better understanding. Open up the interactive python shell in the directory \u2018distributor_service\u2019 by typing (You can also create and execute this in a script) sudo python3 Add appropriate imports: (\u2018example.py\u2019 holds some tasksets for testing, \u2018loggingMonitor.py\u2019 is a Monitor for testing, which writes to logs/monitor.log) from malsamiTest import example5 from monitors.loggingMonitor import LoggingMonitor from distributor import Distributor Defining a monitor and tasksets for the execution is left to the user. Initialize modules: t = example5() lm = LoggingMonitor() dist = Distributor() Now the distributor is running. Adding a job is possible via the add_jobs(taskset, monitor) function: dist.add_job(t,lm) This will spawn machines acording to the current max_machine value. Note: You can repeat the above command to queue multiple jobs whenever you please. To view a list of detached qemu instances sudo screen -ls To kill a detached screen type: sudo screen -X -S <name\\_of\\_screen> kill The log files of the genode instances are also saved in the log/ directory. Additionally, you can adjust the number of spawned machines, also while the distributor is running. See the distributor functions for more information. Distributor functions \u00b6 Setting max machines to a value between 1 and 42. You can change this anytime as this only affects the maximum total number of spawned machines. If machines are active, the number will be adapted accordingly. Closing machines will still finish their current taskset before shutting down. set_max_machine_value(numMachines) Function to check if the distributor is busy or not. get_distributor_state() Return current maximum value of possible active machines get_max_machine_value() Creating a new job and adding it to a list of jobs to be worked on. The function is instantiating a new object of type TaskSetQueue which is then appended to the list of jobs to be processed. add_job(taskset, monitor, *session_parameters) A job always consists of Taskset t and a Monitor, the session_parameters are optional. Inside the method a TaskSetQueue will hold the iterator which is returned by t.variants() Kill all machines that are currently running kill_all_machines() The Machine class \u00b6 The \u2018machine.py\u2019 implements a class which extends threading.Thread. An instance of Machine is taking care of spawning a host, creating a session which connects to the spawned host and acquiring tasksets while there still is work to be done.","title":"Distributor"},{"location":"data-generation/distributor/#distributor","text":"Distributor is the main class/entity that controls and distributes host sessions to manage tasksets. Upon startup, the distributor will have a preset value of one host session that it will be able to spawn. The user is permitted to change this number at any time up to a hardcoded limit of forty one. Machines set to be closed will finish their assigned taskset before being shut down. The distributor is mainly used for gathering large-scale data about autonomous system schedulability-tasks, which can be used for data mining and analysis.","title":"Distributor"},{"location":"data-generation/distributor/#set-up-and-configuration","text":"Clone the client-tools repository and initialize the submodules and place a working image.elf file inside the client-tools directory.","title":"Set up and Configuration"},{"location":"data-generation/distributor/#with-vagrant","text":"A vagrant script is provided in the client-tools repository, which will set up the appropriate development environment and prepare it for use without any manual installation or configuration. (Executing the distributor inside a vagrant machine leads to an unknown error, which stops the execution at some point after about ten to thirty hours. As the vagrant machine serves only as a test and development environment, this is not a critical issue and will not be further investigated, as mentioned in the according issue )","title":"With Vagrant"},{"location":"data-generation/distributor/#manual-setup","text":"Install Python 3.5 and pip3 sudo apt-get install python3.5 -qq sudo apt-get install python3-pip -qq Install the requirements for the taskgen module sudo pip3 install -r client-tools/taskgen/requirements.txt Install bridge functionality for networking: sudo apt-get install bridge-utils -qq Download DHCP service and move provided configuration file. sudo apt-get install isc-dhcp-server -qq sudo cp dhcpd.conf /etc/dhcp/ Set up the bridge and assign an IP address (consult the dhcp.conf file for more information on IP ranges) sudo brctl addbr br0 sudo ip addr add 10.200.40.1/21 dev br0 Adjust /etc/network/interfaces file with preliminary networking information sudo sh -c 'echo \"auto br0\\niface br0 inet dhcp\\nbridge_ports eth0\\nbridge_stp off\\nbridge_maxwait 0\\nbridge_fd 0\\n\" >> /etc/network/interfaces' Install qemu and screen for spawning host sessions from the distributor and for easy visualization of spawned sessions. sudo apt-get install qemu -qq sudo apt-get install screen -qq Start the dhcp service sudo systemctl start isc-dhcp-server The machine should now be ready for use.","title":"Manual Setup"},{"location":"data-generation/distributor/#using-the-distributor","text":"The following is an example execution to provide better understanding. Open up the interactive python shell in the directory \u2018distributor_service\u2019 by typing (You can also create and execute this in a script) sudo python3 Add appropriate imports: (\u2018example.py\u2019 holds some tasksets for testing, \u2018loggingMonitor.py\u2019 is a Monitor for testing, which writes to logs/monitor.log) from malsamiTest import example5 from monitors.loggingMonitor import LoggingMonitor from distributor import Distributor Defining a monitor and tasksets for the execution is left to the user. Initialize modules: t = example5() lm = LoggingMonitor() dist = Distributor() Now the distributor is running. Adding a job is possible via the add_jobs(taskset, monitor) function: dist.add_job(t,lm) This will spawn machines acording to the current max_machine value. Note: You can repeat the above command to queue multiple jobs whenever you please. To view a list of detached qemu instances sudo screen -ls To kill a detached screen type: sudo screen -X -S <name\\_of\\_screen> kill The log files of the genode instances are also saved in the log/ directory. Additionally, you can adjust the number of spawned machines, also while the distributor is running. See the distributor functions for more information.","title":"Using the Distributor"},{"location":"data-generation/distributor/#distributor-functions","text":"Setting max machines to a value between 1 and 42. You can change this anytime as this only affects the maximum total number of spawned machines. If machines are active, the number will be adapted accordingly. Closing machines will still finish their current taskset before shutting down. set_max_machine_value(numMachines) Function to check if the distributor is busy or not. get_distributor_state() Return current maximum value of possible active machines get_max_machine_value() Creating a new job and adding it to a list of jobs to be worked on. The function is instantiating a new object of type TaskSetQueue which is then appended to the list of jobs to be processed. add_job(taskset, monitor, *session_parameters) A job always consists of Taskset t and a Monitor, the session_parameters are optional. Inside the method a TaskSetQueue will hold the iterator which is returned by t.variants() Kill all machines that are currently running kill_all_machines()","title":"Distributor functions"},{"location":"data-generation/distributor/#the-machine-class","text":"The \u2018machine.py\u2019 implements a class which extends threading.Thread. An instance of Machine is taking care of spawning a host, creating a session which connects to the spawned host and acquiring tasksets while there still is work to be done.","title":"The Machine class"},{"location":"data-generation/monitor/","text":"Monitor \u00b6 This section is supposed to provide insight on the monitor component and how it is intended to be used. The monitor has to be provided alongside the taskset component to the add_jobs() function of the distributor. The monitors functions are called in run() of the machine.py . A monitor has to implement the AbstractMonitor in the distributor_service module which defines the following abstract methods: __taskset_event__(taskset, event) \u00b6 This function is called when the session.run() as soon as new information about the taskset is returned from Genode. __taskset_start__(taskset) \u00b6 This function is called when a new taskset has benn started by calling the session.start() function. __taskset_stop__(taskset) \u00b6 This function is called when a new taskset has benn started by calling the session.stop() function. If this function is called the monitor regards the taskset as completed and all information, which could be gained is available. __taskset_finish__(self, taskset) \u00b6 In general the monitor functions always hold a reference to the taskset the function was called with, so it has access to all information saved in the obect defined by the task.py .","title":"Monitor"},{"location":"data-generation/monitor/#monitor","text":"This section is supposed to provide insight on the monitor component and how it is intended to be used. The monitor has to be provided alongside the taskset component to the add_jobs() function of the distributor. The monitors functions are called in run() of the machine.py . A monitor has to implement the AbstractMonitor in the distributor_service module which defines the following abstract methods:","title":"Monitor"},{"location":"data-generation/monitor/#9595taskset95event9595taskset-event","text":"This function is called when the session.run() as soon as new information about the taskset is returned from Genode.","title":"__taskset_event__(taskset, event)"},{"location":"data-generation/monitor/#9595taskset95start9595taskset","text":"This function is called when a new taskset has benn started by calling the session.start() function.","title":"__taskset_start__(taskset)"},{"location":"data-generation/monitor/#9595taskset95stop9595taskset","text":"This function is called when a new taskset has benn started by calling the session.stop() function. If this function is called the monitor regards the taskset as completed and all information, which could be gained is available.","title":"__taskset_stop__(taskset)"},{"location":"data-generation/monitor/#9595taskset_finish9595self-taskset","text":"In general the monitor functions always hold a reference to the taskset the function was called with, so it has access to all information saved in the obect defined by the task.py .","title":"__taskset_finish__(self, taskset)"},{"location":"genode/genode/","text":"Genode & Fiasco Update \u00b6 This section covers the updates for Genode and Fiasco.OC. Agenda \u00b6 + + Setup \u00b6 The default setup listed below is based on Genode 16.08 and foc r67. To use the new versions Genode 18.02 and foc r78 please take a look at \u201cStructure of directories\u201d. If you like to use a VM for this project, please follow the steps on the ArgOS-research website . If you like to use your native machine, just clone https://github.com/argos-research/operating-system.git branch master and execute ./setup.sh . This will build the project \u201cdom0-HW\u201d on platform \u201cfocnados_panda\u201d by default. Please adjust the MAKEFILE to your needs. Structure of directories \u00b6 Genode 18.02 and foc r78: https://github.com/malsami/genode branch 18.02_r78 Genode 18.02 and focnados r78: https://github.com/malsami/genode branch focnados_18.02_r78 Checkpoint Restore and Taskloader for Genode 18.02 and focnados r78: https://github.com:argos-research/operating-system.git branch 18.02","title":"Genode"},{"location":"genode/genode/#genode-fiasco-update","text":"This section covers the updates for Genode and Fiasco.OC.","title":"Genode &amp; Fiasco Update"},{"location":"genode/genode/#agenda","text":"+ +","title":"Agenda"},{"location":"genode/genode/#setup","text":"The default setup listed below is based on Genode 16.08 and foc r67. To use the new versions Genode 18.02 and foc r78 please take a look at \u201cStructure of directories\u201d. If you like to use a VM for this project, please follow the steps on the ArgOS-research website . If you like to use your native machine, just clone https://github.com/argos-research/operating-system.git branch master and execute ./setup.sh . This will build the project \u201cdom0-HW\u201d on platform \u201cfocnados_panda\u201d by default. Please adjust the MAKEFILE to your needs.","title":"Setup"},{"location":"genode/genode/#structure-of-directories","text":"Genode 18.02 and foc r78: https://github.com/malsami/genode branch 18.02_r78 Genode 18.02 and focnados r78: https://github.com/malsami/genode branch focnados_18.02_r78 Checkpoint Restore and Taskloader for Genode 18.02 and focnados r78: https://github.com:argos-research/operating-system.git branch 18.02","title":"Structure of directories"},{"location":"machine-learning/Analysis_Visualization/","text":"Given the nature of the original data, the parameters were not too different and it was difficult to do any machine learning tasks on it. Furthermore, the parameters used were not too descriptive. For the new data, we are making use of newer parameters priority, deadline, period, critical time, number of jobs, offset, quota, caps, cores, core offset, arg . taskParameters = { \u2018PKG\u2019: {1:\u2019hey\u2019, 2:\u2019pi\u2019, 3:\u2019tumatmul\u2019, 4:\u2019cond_mod\u2019#, #5:\u2019cond_42\u2019 }, \u2018PRIORITY\u2019: (1,5),#127), # think we can put constraint on this and just provide maybe 5 different values, so values appear more often and in the end with fp scheduling only the difference should matter(?) \u2018DEADLINE\u2019 : (0, 0), \u2018PERIOD\u2019: (1,8), \u2018CRITICALTIME\u2019 : (0, 0), # is assigned by function depending on PERIOD \u2018NUMBEROFJOBS\u2019: (1,8),#(1,10), \u2018OFFSET\u2019: (0,0), \u2018QUOTA\u2019: (100, 100), #(1, 100),# we could just assign arbitrary big values to this and to caps as well, cause a working task, which is the assumption for an initial taskset, would have good values for that and both (caps and ram) are available in abundance \u2018CAPS\u2019: (235, 235), #(10, 235) \u2018CORES\u2019 : (0, 0), \u2018COREOFFSET\u2019 : (0, 0), \u2018ARG\u2019: {\u2018hey\u2019:(0,0),#23-28 \u2018pi\u2019:(13,21),#84-1600 \u2018tumatmul\u2019:(12,19),#104-2700 \u2018cond_mod\u2019:(25,30)#,#130-3000 #\u2019cond_42\u2019:(2,4) } } In the example above, the indicated values (a,b) indicates the parameter value will be in the range between a and b. As shown above, some parameters such as CAPS , COREOFFSET , OFFSET , DEADLINE , QUOTA will all remain constant due to how Genode works. Although we need these parameters in order to simulate the tasks, their constant nature will not give any further analysis in terms of Genode. Therefore, we will turn our focus to the parameters that are variable. This will give a better understanding on whether these parameters have any influence on success of the tasksets.","title":"Analysis Visualization"},{"location":"machine-learning/deep-learning/","text":"Deep Learning \u00b6 The use of deep learning has pervaded aritificial intelligence and is being applied to virtually all projects. Deep Learning\u2019s strengths lie in its ability to pattern match data with complicated structures given that it has enough training data. Although deep learning seems to be the obvious answer with its advanced techniques, it is relatively heavyweight. Deep Learning works best when there is a lot of data to sample from and if possible, if we have an idea of what the data is like. There are virtually endless number of deep learning models that are possible to try out. We have listed a few of them below. Feed Forward Neural Network \u00b6 A Feed-forward artificial neural network is a multilayer perceptron and is the most basic neural network available. A feed forward network is a necessary model and will act as the control network for the rest of the deep learning models. Feed Forward Networks are adaptable in fitting simple data. We hope to acheive as high of a possible of an accuracy on this type of network before venturing into the more advanced networks listed below. A simple Feed Forward Net has already been trained and fitted with some success (80% accuracy.) An implementation for a basic Feed Forward Network already exists. The repo and expansive documentation is provided here . Recurrent Neural Networks \u00b6 Recurrent Neural Networks are types of networks which utilizes \u2018memory\u2019. These networks are very similiar to regular feed forward networks except for their ability to process previously analyzed along with the data that is currently being processed. These types of networks are especially beneficial for temporal and sequence analysis. This type of network could prove to be fruitful in the online learning phase as this network can better analyze recent events and use them in the learning process. At the same time, thie network will still be heavy duty and possibly computationally more expensive than the regular feed-forward network. Generative Adversarial Networks \u00b6 A GAN generally does not describe the structure of the neural network, but rather two types of neural networks which work together (or against each other). One generates data similar to some real dataset and the second network, which was formerly trained on the original dataset evaluates the generated data. The generator intends on \u201cfooling\u201d the evaluating network into classifying the generated data as real. While training, the generator becomes better at creating data close to the real dataset and the evaluating network becomes better at flagging faulty or erroneous data. We can think of the generator as producing the data and the discriminator as a regular supervised network that is no different from the others. The discriminator however can classify real and fake data more accurately. The generator produces samples to \u2018misclassify\u2019 the discriminator while the discriminator is training to counteract it. Convolutional Neural Networks \u00b6 A convolutional networks biggest strength is in its ability to extract the relevant features from an extremely large dataset. Convolutional networks are usually used in image processing as they are effective at processing images based on the information different areas of the image gives. Other than image processing, these types of networks are very good at measuring structured information. This includes text classificatoin and other problems in which the data\u2019s placement gives clues as to its meaning. If the data from the distributor happens to be structured in any way, the convolutional network has a good chance of performing well on it. Spiking Neural Networks \u00b6 Spiking Neural Networks refer to any network in which the input nodes(neurons) propogate the information at different times throughout the network. Each input neuron has an activation level in which incoming spikes determines pushes the function higher or lower. These networks most closely model real neurons in the brain, as all potential information is not fully processed at each time. The problem is that spiking is a noisy process, and may skew the data. The spikes are part of the learning process, and so the times the neurons are activated is analyzed just as much as what the neurons are sending. The idea of spiking can be applied to any of the other neural networks above, as it resembles more of a hyperparameter than an actual unique network model. A network using spiking is difficult to train as the signal nature of the spikes may be non-continuous and non-differentiable.","title":"Deep Learning"},{"location":"machine-learning/deep-learning/#deep-learning","text":"The use of deep learning has pervaded aritificial intelligence and is being applied to virtually all projects. Deep Learning\u2019s strengths lie in its ability to pattern match data with complicated structures given that it has enough training data. Although deep learning seems to be the obvious answer with its advanced techniques, it is relatively heavyweight. Deep Learning works best when there is a lot of data to sample from and if possible, if we have an idea of what the data is like. There are virtually endless number of deep learning models that are possible to try out. We have listed a few of them below.","title":"Deep Learning"},{"location":"machine-learning/deep-learning/#feed-forward-neural-network","text":"A Feed-forward artificial neural network is a multilayer perceptron and is the most basic neural network available. A feed forward network is a necessary model and will act as the control network for the rest of the deep learning models. Feed Forward Networks are adaptable in fitting simple data. We hope to acheive as high of a possible of an accuracy on this type of network before venturing into the more advanced networks listed below. A simple Feed Forward Net has already been trained and fitted with some success (80% accuracy.) An implementation for a basic Feed Forward Network already exists. The repo and expansive documentation is provided here .","title":"Feed Forward Neural Network"},{"location":"machine-learning/deep-learning/#recurrent-neural-networks","text":"Recurrent Neural Networks are types of networks which utilizes \u2018memory\u2019. These networks are very similiar to regular feed forward networks except for their ability to process previously analyzed along with the data that is currently being processed. These types of networks are especially beneficial for temporal and sequence analysis. This type of network could prove to be fruitful in the online learning phase as this network can better analyze recent events and use them in the learning process. At the same time, thie network will still be heavy duty and possibly computationally more expensive than the regular feed-forward network.","title":"Recurrent Neural Networks"},{"location":"machine-learning/deep-learning/#generative-adversarial-networks","text":"A GAN generally does not describe the structure of the neural network, but rather two types of neural networks which work together (or against each other). One generates data similar to some real dataset and the second network, which was formerly trained on the original dataset evaluates the generated data. The generator intends on \u201cfooling\u201d the evaluating network into classifying the generated data as real. While training, the generator becomes better at creating data close to the real dataset and the evaluating network becomes better at flagging faulty or erroneous data. We can think of the generator as producing the data and the discriminator as a regular supervised network that is no different from the others. The discriminator however can classify real and fake data more accurately. The generator produces samples to \u2018misclassify\u2019 the discriminator while the discriminator is training to counteract it.","title":"Generative Adversarial Networks"},{"location":"machine-learning/deep-learning/#convolutional-neural-networks","text":"A convolutional networks biggest strength is in its ability to extract the relevant features from an extremely large dataset. Convolutional networks are usually used in image processing as they are effective at processing images based on the information different areas of the image gives. Other than image processing, these types of networks are very good at measuring structured information. This includes text classificatoin and other problems in which the data\u2019s placement gives clues as to its meaning. If the data from the distributor happens to be structured in any way, the convolutional network has a good chance of performing well on it.","title":"Convolutional Neural Networks"},{"location":"machine-learning/deep-learning/#spiking-neural-networks","text":"Spiking Neural Networks refer to any network in which the input nodes(neurons) propogate the information at different times throughout the network. Each input neuron has an activation level in which incoming spikes determines pushes the function higher or lower. These networks most closely model real neurons in the brain, as all potential information is not fully processed at each time. The problem is that spiking is a noisy process, and may skew the data. The spikes are part of the learning process, and so the times the neurons are activated is analyzed just as much as what the neurons are sending. The idea of spiking can be applied to any of the other neural networks above, as it resembles more of a hyperparameter than an actual unique network model. A network using spiking is difficult to train as the signal nature of the spikes may be non-continuous and non-differentiable.","title":"Spiking Neural Networks"},{"location":"machine-learning/machine-learning/","text":"Machine Learning \u00b6 Machine Learning is a useful tool for pattern matching and curve fitting to make predictions based on data and its underlying patterns. Given the recent breakthroughs and ease of use, it is worthwhile to extend the research of schedulability analysis to the lens of machine learning. These algorithms will be able to interpret the data in much more efficient and feasible ways than other algorithms. Since we are using real-time systems, we must also analyze the efficiency and cost of the algorithms and understand the tradeoffs among different techniques. Certain algorithms may be more suitable for the offline training phase while others on the online training phase. All of these are factors which will be considered with this analysis. The models will be evaluated primarily as a cost benefit analysis with regards to its execution cost (resources required, time to train and classify) and its classification ability. At the very least, machine learning should help to model the data with accuracy where predictions bring more success than standard techniques. We are pursuing both routes with Deep Learning and Shallow_Learning to compare the approaches. Although deep learning models are more flexible and advanced than their shallow learning counterparts, it is important to analyze both to see the tradeoffs of both approaches. Since resources and time of execution are more important to consider in the online than the offline learning phases, it is important to see whether we can emulate the accuracy of a heavyweight neural network with a lighter weight shallow-learning algorithm. Furthermore, different algorithms acheive higher accuracy depending on the modelling of the data. A naive bayes classification with high accuracy will indicate data that is mostly independent and uncorrelated with each other. We hope that testing a wide variety of these approaches will reveal important information for any kind of future schedulability analysis. Understanding the data is the most important aspect and will provide useful information for any kind of feature engineering that may be done in the future. For more information on the specific algorithms, please see the Deep Learning and Shallow_Learning pages.","title":"Machine Learning"},{"location":"machine-learning/machine-learning/#machine-learning","text":"Machine Learning is a useful tool for pattern matching and curve fitting to make predictions based on data and its underlying patterns. Given the recent breakthroughs and ease of use, it is worthwhile to extend the research of schedulability analysis to the lens of machine learning. These algorithms will be able to interpret the data in much more efficient and feasible ways than other algorithms. Since we are using real-time systems, we must also analyze the efficiency and cost of the algorithms and understand the tradeoffs among different techniques. Certain algorithms may be more suitable for the offline training phase while others on the online training phase. All of these are factors which will be considered with this analysis. The models will be evaluated primarily as a cost benefit analysis with regards to its execution cost (resources required, time to train and classify) and its classification ability. At the very least, machine learning should help to model the data with accuracy where predictions bring more success than standard techniques. We are pursuing both routes with Deep Learning and Shallow_Learning to compare the approaches. Although deep learning models are more flexible and advanced than their shallow learning counterparts, it is important to analyze both to see the tradeoffs of both approaches. Since resources and time of execution are more important to consider in the online than the offline learning phases, it is important to see whether we can emulate the accuracy of a heavyweight neural network with a lighter weight shallow-learning algorithm. Furthermore, different algorithms acheive higher accuracy depending on the modelling of the data. A naive bayes classification with high accuracy will indicate data that is mostly independent and uncorrelated with each other. We hope that testing a wide variety of these approaches will reveal important information for any kind of future schedulability analysis. Understanding the data is the most important aspect and will provide useful information for any kind of feature engineering that may be done in the future. For more information on the specific algorithms, please see the Deep Learning and Shallow_Learning pages.","title":"Machine Learning"},{"location":"machine-learning/shallow-learning/","text":"Shallow Learning \u00b6 Shallow Learning represents the techniques that are not \u2018deep learning\u2019 or in the case of this project, those of which do not utilize a neural network or multi-layer perceptron. Although virtually any technique can be tested under the guise of \u2018shallow learning\u2019, we chose to focus on Support Vector Machines, k-Nearest Neibhbors (kNN), Logistic Regression, Gaussian Naive Bayes, and Decision Trees/Random Forests. While these algorithms each have their strenghts and weaknesses, their lightweight and easy implementation makes them easy to test and analyze. From the performance of these various algorithms, we can find import trends in the data. Logistic Regression/Classification \u00b6 Logistic Regression will determine attempt to model any relationship between the measured data and the label data. In the case of taskset data, logistic regression will attemp to model a relationship between the various tasksets. If you are familiar with neural networks, logistic regression is simply a neural network without the hidden layer. It will give weights to the data point(s) based on the features. Naive Bayes Algorithm \u00b6 Naive Bayes algorithm is \u2018naive\u2019 because it implicity assumes independence among all individual training examples. As we know with data systems, let alone taskset data, it is very unlikely that the data is independent. However, if we were to get a good performance with this classificaton algorithm, it would inidcate that the data is uncorrelated. Although more sophisticated algorithms exist, naive bayes is very good for efficient computation. Because of its assumption of independence, the order of the input or the arrangement of the data does not affect the overall training experience. This is especially important in online-learning when all the data is not immediately available to us. K-Nearest Neighbors \u00b6 The K-Nearest Neighbors is one of the simples algorithm that uses rudimentary techniques to classify data. It is a flexible approach and can be useful for determining locality information. This information could further be used for unsupervised learning techniques such as clustering and dimension reduction. Unfortunately, this method does not scale well with multi-feature data similiar to the data that we currently have. However, this algorithm is fairly simple to implement and test. It will serve as a meaningful control algorithm (one in which we compare our fancier algorithms to). Random Forests/Decision Trees \u00b6 Decision Trees are great for handling categorical information without having to do much preprocessing. After the training phase, it is able to classify data quickly. This will be especially useful in the online learning phase. The main issue with decision trees is its likelihood of overfitting. This is where random forests come in to the picture. Random Forests are a very powerful algorithm and handle the low variance issues of decision trees. Although they are a little more difficult to implement/tune, they are expected to be one of the more useful algorithms. Much like decision trees, they can classify test data very quickly. Suppor Vector Machines (svm) \u00b6 Suppor Vector machines are effective classifiers for any kind of classification task. A linear support vector machine may not separate the data as well as a non-linear svm. However, for completeness, we will train several different models on the data to obtain the best fit. Although this is an exhaustive process, support vector machines are relatively lightweight and very highly regarded for binary classification tasks. Additionally, the preproccesing step to divide the classes into respective classification assignments is also important and will assist in more accuracte predictions. We fitted a support vector machine with a polynomial kernel. For completeness, we added functionality for grid search (GridSearchCV) which fits the support vector machine with multiple different hyperparameters. (Note about the grid search, it is an exhaustive execution that will take a lot of time and energy. We recommend enabling GPU support, however it is unclear whether or not performance will ampify as much as it would for deep learning. Do not be surprised by long computation time. A quicker alternative would be to manually tune the hyperparameters with a training and validation set). In general, the Support Vector Machines with the Gaussian kernels perform optimally.","title":"Shallow learning"},{"location":"machine-learning/shallow-learning/#shallow-learning","text":"Shallow Learning represents the techniques that are not \u2018deep learning\u2019 or in the case of this project, those of which do not utilize a neural network or multi-layer perceptron. Although virtually any technique can be tested under the guise of \u2018shallow learning\u2019, we chose to focus on Support Vector Machines, k-Nearest Neibhbors (kNN), Logistic Regression, Gaussian Naive Bayes, and Decision Trees/Random Forests. While these algorithms each have their strenghts and weaknesses, their lightweight and easy implementation makes them easy to test and analyze. From the performance of these various algorithms, we can find import trends in the data.","title":"Shallow Learning"},{"location":"machine-learning/shallow-learning/#logistic-regressionclassification","text":"Logistic Regression will determine attempt to model any relationship between the measured data and the label data. In the case of taskset data, logistic regression will attemp to model a relationship between the various tasksets. If you are familiar with neural networks, logistic regression is simply a neural network without the hidden layer. It will give weights to the data point(s) based on the features.","title":"Logistic Regression/Classification"},{"location":"machine-learning/shallow-learning/#naive-bayes-algorithm","text":"Naive Bayes algorithm is \u2018naive\u2019 because it implicity assumes independence among all individual training examples. As we know with data systems, let alone taskset data, it is very unlikely that the data is independent. However, if we were to get a good performance with this classificaton algorithm, it would inidcate that the data is uncorrelated. Although more sophisticated algorithms exist, naive bayes is very good for efficient computation. Because of its assumption of independence, the order of the input or the arrangement of the data does not affect the overall training experience. This is especially important in online-learning when all the data is not immediately available to us.","title":"Naive Bayes Algorithm"},{"location":"machine-learning/shallow-learning/#k-nearest-neighbors","text":"The K-Nearest Neighbors is one of the simples algorithm that uses rudimentary techniques to classify data. It is a flexible approach and can be useful for determining locality information. This information could further be used for unsupervised learning techniques such as clustering and dimension reduction. Unfortunately, this method does not scale well with multi-feature data similiar to the data that we currently have. However, this algorithm is fairly simple to implement and test. It will serve as a meaningful control algorithm (one in which we compare our fancier algorithms to).","title":"K-Nearest Neighbors"},{"location":"machine-learning/shallow-learning/#random-forestsdecision-trees","text":"Decision Trees are great for handling categorical information without having to do much preprocessing. After the training phase, it is able to classify data quickly. This will be especially useful in the online learning phase. The main issue with decision trees is its likelihood of overfitting. This is where random forests come in to the picture. Random Forests are a very powerful algorithm and handle the low variance issues of decision trees. Although they are a little more difficult to implement/tune, they are expected to be one of the more useful algorithms. Much like decision trees, they can classify test data very quickly.","title":"Random Forests/Decision Trees"},{"location":"machine-learning/shallow-learning/#suppor-vector-machines-svm","text":"Suppor Vector machines are effective classifiers for any kind of classification task. A linear support vector machine may not separate the data as well as a non-linear svm. However, for completeness, we will train several different models on the data to obtain the best fit. Although this is an exhaustive process, support vector machines are relatively lightweight and very highly regarded for binary classification tasks. Additionally, the preproccesing step to divide the classes into respective classification assignments is also important and will assist in more accuracte predictions. We fitted a support vector machine with a polynomial kernel. For completeness, we added functionality for grid search (GridSearchCV) which fits the support vector machine with multiple different hyperparameters. (Note about the grid search, it is an exhaustive execution that will take a lot of time and energy. We recommend enabling GPU support, however it is unclear whether or not performance will ampify as much as it would for deep learning. Do not be surprised by long computation time. A quicker alternative would be to manually tune the hyperparameters with a training and validation set). In general, the Support Vector Machines with the Gaussian kernels perform optimally.","title":"Suppor Vector Machines (svm)"},{"location":"machine-learning/nets/ffn/","text":"Feed Forward Network Documentation \u00b6 This was a four layers feed forward neural network with two hidden layers of arbitrary length. The hidden layers each had leaky-RELU non-linearities. The input dimension (N X D) constituted the number of tasksets (N) where each taskset contained a certain number of tasks. The parameters of these individual tasks within the taskset made up the parameters/features of the taskset itself. The output dimension (H2 X 1) was a single neuron which outputs a \u20181\u2019 or \u20180\u2019 using a sigmoid function. The code is available here . The user can determine how many hidden units he or she would like to use. He or she is also allowed to decide on the number of epochs and the learning rate. This gives the user a bit of flexibility in fitting the model to the task data. Although ReLU functions are very popular with most Feed-Forward Neural Networks. ReLU functions are popular because of their handling of the vanishing gradient that often arises from other activation functions. The advantage of Leaky ReLU is that it preserves more of the data than a regular ReLU function. While the ReLU chooses the max(0,input), the leaky-ReLU will choose: $ \\begin{array}{cc} { & \\begin{array}{cc} 0 & x\\leq 0 \\ \\frac{100-x}{100} & 0\\leq x\\leq 100 \\ 0 & 100\\leq x \\end{array} \\end{array} $","title":"Feed Forward Network"},{"location":"machine-learning/nets/ffn/#feed-forward-network-documentation","text":"This was a four layers feed forward neural network with two hidden layers of arbitrary length. The hidden layers each had leaky-RELU non-linearities. The input dimension (N X D) constituted the number of tasksets (N) where each taskset contained a certain number of tasks. The parameters of these individual tasks within the taskset made up the parameters/features of the taskset itself. The output dimension (H2 X 1) was a single neuron which outputs a \u20181\u2019 or \u20180\u2019 using a sigmoid function. The code is available here . The user can determine how many hidden units he or she would like to use. He or she is also allowed to decide on the number of epochs and the learning rate. This gives the user a bit of flexibility in fitting the model to the task data. Although ReLU functions are very popular with most Feed-Forward Neural Networks. ReLU functions are popular because of their handling of the vanishing gradient that often arises from other activation functions. The advantage of Leaky ReLU is that it preserves more of the data than a regular ReLU function. While the ReLU chooses the max(0,input), the leaky-ReLU will choose: $ \\begin{array}{cc} { & \\begin{array}{cc} 0 & x\\leq 0 \\ \\frac{100-x}{100} & 0\\leq x\\leq 100 \\ 0 & 100\\leq x \\end{array} \\end{array} $","title":"Feed Forward Network Documentation"}]}