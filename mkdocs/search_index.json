{
    "docs": [
        {
            "location": "/",
            "text": "MaLSAMi project documentation\n\n\nWelcome to the MaLSAMi project documentation.\n\n\nIn here we will document our progress and almost all subprojects or programs\nwe will create or write.\nIf you want to take a deeper look in our open source code projects please refer to the \nMaLSAMi Github Page\n\n\nAbout the project\n\n\nYou can find a general description of the project MaLSAMi in the \nAbout Section\n\n\nPrerequisite\n\n\nTo contribute to this documentation please download the source code from the \nMaLSAMi Documentation Repository\n\nand follow the instructions at \nMkDocs\n.\n\n\nDocumentation structure\n\n\nThe documentation is structured into different subpages which are representing subprojects of the project MaLSAMi.\nNevertheless also analysis results or specifications of the projects can be described in a subpage.\n\n\nCommands\n\n\nTo work with MkDocs after installing it, you can use these commands\n\n\n\n\nmkdocs serve\n - Start the live-reloading docs server.\n\n\nmkdocs build\n - Build the documentation site.\n\n\nmkdocs help\n - Print this help message.\n\n\n\n\nTo upload the documentation to the git repository please following command, but be aware that changes might be immediately visible.\n\n\n\n\nmkdocs gh-deploy\n - Uploads build documentation sites to gh-pages branch\n\n\n\n\nProject layout\n\n\nmkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.",
            "title": "Home"
        },
        {
            "location": "/#malsami-project-documentation",
            "text": "Welcome to the MaLSAMi project documentation.  In here we will document our progress and almost all subprojects or programs\nwe will create or write.\nIf you want to take a deeper look in our open source code projects please refer to the  MaLSAMi Github Page",
            "title": "MaLSAMi project documentation"
        },
        {
            "location": "/#about-the-project",
            "text": "You can find a general description of the project MaLSAMi in the  About Section",
            "title": "About the project"
        },
        {
            "location": "/#prerequisite",
            "text": "To contribute to this documentation please download the source code from the  MaLSAMi Documentation Repository \nand follow the instructions at  MkDocs .",
            "title": "Prerequisite"
        },
        {
            "location": "/#documentation-structure",
            "text": "The documentation is structured into different subpages which are representing subprojects of the project MaLSAMi.\nNevertheless also analysis results or specifications of the projects can be described in a subpage.",
            "title": "Documentation structure"
        },
        {
            "location": "/#commands",
            "text": "To work with MkDocs after installing it, you can use these commands   mkdocs serve  - Start the live-reloading docs server.  mkdocs build  - Build the documentation site.  mkdocs help  - Print this help message.   To upload the documentation to the git repository please following command, but be aware that changes might be immediately visible.   mkdocs gh-deploy  - Uploads build documentation sites to gh-pages branch",
            "title": "Commands"
        },
        {
            "location": "/#project-layout",
            "text": "mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.",
            "title": "Project layout"
        },
        {
            "location": "/Deep_Learning/",
            "text": "Deep Learning\n\n\nThe use of deep learning has pervaded aritificial intelligence and is being applied to virtually all projects. Deep Learning's strengths lie in its ability to pattern match data with complicated structures given that it has enough training data. Although deep learning seems to be the obvious answer with its advanced techniques, it is relatively heavyweight. Deep Learning works best when there is a lot of data to sample from and if possible, if we have an idea of what the data is like.  \n\n\nThere are virtually endless number of deep learning models that are possible to try out. We have listed a few of them below. \n\n\nFeed Forward Neural Network\n\n\nA Feed-forward artificial neural network is a multilayer perceptron and is the most basic neural network available. A feed forward network is a necessary model and will act as the \ncontrol\n network for the rest of the deep learning models. Feed Forward Networks are adaptable in fitting simple data. We hope to acheive as high of a possible of an accuracy on this type of network before venturing into the more advanced networks listed below. A simple Feed Forward Net has already been trained and fitted with some success (80% accuracy.)\n\n\nAn implementation for a basic Feed Forward Network already exists. The repo and expansive documentation is provided \nhere\n. \n\n\nRecurrent Neural Networks\n\n\nRecurrent Neural Networks are types of networks which utilizes 'memory'. These networks are very similiar to regular feed forward networks except for their ability to process previously analyzed along with the data that is currently being processed. These types of networks are especially beneficial for temporal and sequence analysis. This type of network could prove to be fruitful in the online learning phase as this network can better analyze recent events and use them in the learning process. At the same time, thie network will still be heavy duty and possibly computationally more expensive than the regular feed-forward network. \n\n\nGenerative Adversarial Networks\n\n\nA GAN generally does not describe the structure of the neural network, but rather two types of neural networks which work together (or against each other). One generates data similar to some real dataset and the second network, which was formerly trained on the original dataset evaluates the generated data. The generator intends on \"fooling\" the evaluating network into classifying the generated data as real. While training, the generator becomes better at creating data close to the real dataset and the evaluating network becomes better at flagging faulty or erroneous data. \n\n\nTypically the generator is a deconvolutional network, often generating images, while the second network is a convolutional network, evaluating the image.\n\n\nConvolutional Neural Networks\n\n\nA convolutional networks biggest strength is in its ability to extract the relevant features from an extremely large dataset. Convolutional networks are usually used in image processing as they are effective at processing images based on the information different areas of the image gives. Other than image processing, these types of networks are very good at measuring structured information. This includes text classificatoin and other problems in which the data's placement gives clues as to its meaning. If the data from the distributor happens to be structured in any way, the convolutional network has a good chance of performing well on it. \n\n\nSpiking Neural Networks\n\n\nSpiking Neural Networks refer to any network in which the input nodes(neurons) propogate the information at different times throughout the network. Each input neuron has an activation level in which incoming spikes determines pushes the function higher or lower. These networks most closely model real neurons in the brain, as all potential information is not fully processed at each time. The problem is that spiking is a noisy process, and may skew the data. The spikes are part of the learning process, and so the times the neurons are activated is analyzed just as much as what the neurons are sending. The idea of spiking can be applied to any of the other neural networks above, as it resembles more of a hyperparameter than an actual unique network model. A network using spiking is difficult to train as the signal nature of the spikes may be non-continuous and non-differentiable.",
            "title": "Deep Learning"
        },
        {
            "location": "/Feed_Forward_Net/",
            "text": "Feed Forward Network Documentation",
            "title": "Feed Forward Net"
        },
        {
            "location": "/Shallow_Learning/",
            "text": "Shallow Learning\n\n\nShallow Learning represents the techniques that are not 'deep learning' or in the case of this project, those of which do not utilize a neural network or multi-layer perceptron. The algorithms that will be tested under the topic of 'shallow learning' are Support Vector Machines, k-Nearest Neibhbors (kNN), Logistic Regression, Gaussian Naive Bayes, and Decision Trees/Random Forests. These algorithms' performances should give insight into the types of data we are seeing. From this, we can decide on better ways to fit the data. \n\n\nLogistic Regression/Classification\n\n\nWe simply took the original feed forward network and removed the hidden layer to fit it with the data. Like the neural networks, we initialized with random weights and then trained it extensively to find the correct weights. This falls under the same stochastic error problems as a neural network does. \n\n\nThe logistic regression approach is similiar to the Feed Forward Neural Network without the hidden layer. As the name suggests, we can use logistic regression simplly for predicting a continuous value. \n\n\nOne vs. Rest\n\n\nA common classification problem. This is classifying a certain subset of the data as 'relevant' and the rest of the data as 'irrelevant'. \n\n\nOne vs One (Characterizing certain as relevant and the others as irrelevant)\n\n\nSimiliar to one vs one, however we are characterizing the irrelevant subset of data as being of one class while the 'relevant' subset is of another class. \n\n\nNaive Bayes Algorithm\n\n\nImplement naive bayes algorithm\n\n\nSupport Vector Machines\n\n\nWe fitted a support vector machine with a polynomial kernel. For completeness, we added functionality for grid search (GridSearchCV) which fits the support vector machine with multiple different hyperparameters. (Note about the grid search, it is an exhaustive execution that will take a lot of time and energy. We recommend enabling GPU support, however it is unclear whether or not performance will ampify as much as it would for deep learning. Do not be surprised by long computation time. A quicker alternative would be to manually tune the hyperparameters with a training and validation set). \n\n\nIn general, the Support Vector Machines with the Gaussian kernels perform optimally. \n\n\nK-Nearest Neighbors\n\n\nVery simple approach that is good for determining locality of data. Could be useful for clustering and dimension reduction. This method does not scale well with extra features/dimensions and so is not a viable choice. However, it is a fairly easy algorithm as it barely takes any training time. However, depending on the value of 'K', the classification for new tasks could take some time. \n\n\nRandom Forests/Decision Trees\n\n\nRandom Forests are cool. Its main benefit is the ease of use and the quick classification. Furthemore, it does not require as much of a preprocessing as other algorithms as it can deal with virtually any kind of data. This is a viable candidate for the online learning as it will be useful in performing quick classification with likely high accuracy. \n\n\nThe random forest is good to prevent overfitting from a decision tree. \n\n\nIt is unlikely that the decision tree would perform better that the random forest. For completeness, we will first the data with the decision tree and use the results to better build the random forest to better fit the model. \n\n\nThese random forests have numerous different applications and could very well fit this data will. \n\n\nSuppor Vector Machines\n\n\nSuppor Vector machines are effective classifiers for any kind of classification task. A linear support vector machine is unlikely to linearly separate the data and so a polynomial is the first hypothesized choice. However, for completeness, we will train several different models on the data to obtain the best fit. Although this is an exhaustive process, support vector machines are relatively lightweight and very high regarded for classification tasks. Additionally, the preproccesing step to divide the classes into respective classification assignments is also important and will assist in more accuracte predictions. \n\n\nK-Nearest Neighbor\n\n\nThis is a simple clustering technique. An unlikely optimal fitting algorithm, but must be tested for completeness and comparison. The benefit of this approach is its ability to handle noisy and large amounts of data in a relatively simple way. Noisy and faulty data is very likely to happen in this case with all the data that will be gathered by the distributor. However, data with multiple features will not be well represented by this algorithm as it fails to scale in multiple dimensions. The accuracy (or non-accuracy) of this algorithm will give insight into the number of features and the natural grouping of the data. This can asssist in the other more specialized neural networks (most notably the convolutional neural networks). \n\n\nLogistic Regression\n\n\nThis approach is good at formulizing a pattern based on the previous data analyzed. The issues are its likeliness to overfit while trying to learn more complicated data. However, when there is not much noise in the data, this algorithm is likely to perform very well as it can easily establish a relationship which explains not only the learned data but also to predict newer data. This algorithm will be useful in understanding any kind of correlation or imminent structure in the data. Logistic Regression is easy to optimize because of its convex objective function. \n\n\nGaussian Naive Bayes\n\n\nA simple and easy algorithm that should be the baseline performance in which the other algorithms are measured. A simple math formula which is easy to calculate and requires virtually no extra overhead. \n\n\nDecision Trees/Random Forest\n\n\nDecision Trees are beneficial for their ability to process and classify virtually any type of data. Random Forests are more advanced version of decision trees and usually perform very well. Both can be tested. However, the random forest is the more likely algorithm. \n\n\ntarget: online scheduling on RT systems",
            "title": "Shallow Learning"
        },
        {
            "location": "/Shallow_Learning/#one-vs-rest",
            "text": "A common classification problem. This is classifying a certain subset of the data as 'relevant' and the rest of the data as 'irrelevant'.",
            "title": "One vs. Rest"
        },
        {
            "location": "/Shallow_Learning/#one-vs-one-characterizing-certain-as-relevant-and-the-others-as-irrelevant",
            "text": "Similiar to one vs one, however we are characterizing the irrelevant subset of data as being of one class while the 'relevant' subset is of another class.   Naive Bayes Algorithm  Implement naive bayes algorithm  Support Vector Machines  We fitted a support vector machine with a polynomial kernel. For completeness, we added functionality for grid search (GridSearchCV) which fits the support vector machine with multiple different hyperparameters. (Note about the grid search, it is an exhaustive execution that will take a lot of time and energy. We recommend enabling GPU support, however it is unclear whether or not performance will ampify as much as it would for deep learning. Do not be surprised by long computation time. A quicker alternative would be to manually tune the hyperparameters with a training and validation set).   In general, the Support Vector Machines with the Gaussian kernels perform optimally.   K-Nearest Neighbors  Very simple approach that is good for determining locality of data. Could be useful for clustering and dimension reduction. This method does not scale well with extra features/dimensions and so is not a viable choice. However, it is a fairly easy algorithm as it barely takes any training time. However, depending on the value of 'K', the classification for new tasks could take some time.   Random Forests/Decision Trees  Random Forests are cool. Its main benefit is the ease of use and the quick classification. Furthemore, it does not require as much of a preprocessing as other algorithms as it can deal with virtually any kind of data. This is a viable candidate for the online learning as it will be useful in performing quick classification with likely high accuracy.   The random forest is good to prevent overfitting from a decision tree.   It is unlikely that the decision tree would perform better that the random forest. For completeness, we will first the data with the decision tree and use the results to better build the random forest to better fit the model.   These random forests have numerous different applications and could very well fit this data will.   Suppor Vector Machines  Suppor Vector machines are effective classifiers for any kind of classification task. A linear support vector machine is unlikely to linearly separate the data and so a polynomial is the first hypothesized choice. However, for completeness, we will train several different models on the data to obtain the best fit. Although this is an exhaustive process, support vector machines are relatively lightweight and very high regarded for classification tasks. Additionally, the preproccesing step to divide the classes into respective classification assignments is also important and will assist in more accuracte predictions.   K-Nearest Neighbor  This is a simple clustering technique. An unlikely optimal fitting algorithm, but must be tested for completeness and comparison. The benefit of this approach is its ability to handle noisy and large amounts of data in a relatively simple way. Noisy and faulty data is very likely to happen in this case with all the data that will be gathered by the distributor. However, data with multiple features will not be well represented by this algorithm as it fails to scale in multiple dimensions. The accuracy (or non-accuracy) of this algorithm will give insight into the number of features and the natural grouping of the data. This can asssist in the other more specialized neural networks (most notably the convolutional neural networks).   Logistic Regression  This approach is good at formulizing a pattern based on the previous data analyzed. The issues are its likeliness to overfit while trying to learn more complicated data. However, when there is not much noise in the data, this algorithm is likely to perform very well as it can easily establish a relationship which explains not only the learned data but also to predict newer data. This algorithm will be useful in understanding any kind of correlation or imminent structure in the data. Logistic Regression is easy to optimize because of its convex objective function.   Gaussian Naive Bayes  A simple and easy algorithm that should be the baseline performance in which the other algorithms are measured. A simple math formula which is easy to calculate and requires virtually no extra overhead.   Decision Trees/Random Forest  Decision Trees are beneficial for their ability to process and classify virtually any type of data. Random Forests are more advanced version of decision trees and usually perform very well. Both can be tested. However, the random forest is the more likely algorithm.   target: online scheduling on RT systems",
            "title": "One vs One (Characterizing certain as relevant and the others as irrelevant)"
        },
        {
            "location": "/about/",
            "text": "Goal of the project\n\n\nThis project is about schedulability analysis.",
            "title": "About"
        },
        {
            "location": "/distributor/",
            "text": "Distributor\n\n\nDistributor is the main class/entity that controls and distributes host sessions to manage tasksets. Upon startup, the distributor will have a preset value of one host session that it will be able to spawn. The user is permitted to change this number at any time up to a hardcoded limit of forty one. Machines set to be closed will finish their assigned taskset before being shut down. The distributor is mainly used for gathering large-scale data about autonomous system schedulability-tasks, which can be used for data mining and analysis. \n\n\nSet up and Configuration\n\n\nClone the client-tools repository and initialize the submodules and place a working \nimage.elf\n file inside the client-tools directory.\n\n\nWith Vagrant\n\n\nA \nvagrant\n script is provided in the client-tools repository, which will set up the appropriate development environment and prepare it for use without any manual installation or configuration.\n\n\n(Executing the distributor inside a vagrant machine leads to an unknown error, which stops the execution at some point after about ten to thirty hours. As the vagrant machine serves only as a test and development environment, this is not a critical issue and will not be further investigated, as mentioned in the according \nissue\n)\n\n\nManual Setup\n\n\nInstall Python 3.5 and pip3\n\n\nsudo apt-get install python3.5 -qq\nsudo apt-get  install python3-pip -qq\n\n\n\nInstall the requirements for the taskgen module\n\n\nsudo pip3 install -r client-tools/taskgen/requirements.txt\n\n\n\nInstall bridge functionality for networking:\n\n\nsudo apt-get install bridge-utils -qq\n\n\n\nDownload DHCP service and move provided configuration file. \n\n\nsudo apt-get install isc-dhcp-server -qq\nsudo cp dhcpd.conf /etc/dhcp/\n\n\n\nSet up the bridge and assign an IP address (consult the dhcp.conf file for more information on IP ranges)\n\n\nsudo brctl addbr br0\nsudo ip addr add 10.200.40.1/21 dev br0\n\n\n\nAdjust /etc/network/interfaces file with preliminary networking information\n\n\nsudo sh -c 'echo \"auto br0\\niface br0 inet dhcp\\nbridge_ports eth0\\nbridge_stp off\\nbridge_maxwait 0\\nbridge_fd 0\\n\" >> /etc/network/interfaces'\n\n\n\nInstall qemu and screen for spawning host sessions from the distributor and for easy visualization of spawned sessions. \n\n\nsudo apt-get install qemu -qq\nsudo apt-get install screen -qq\n\n\n\nStart the dhcp service\n\n\nsudo systemctl start isc-dhcp-server\n\n\n\nThe machine should now be ready for use. \n\n\nUsing the Distributor\n\n\nThe following is an example execution to provide better understanding.\n\n\nOpen up the interactive python shell\n in the directory 'distributor_service' by typing (You can also create and execute this in a script)\n\n\nsudo python3\n\n\n\nAdd appropriate imports:\n \n\n\n('example.py' holds some tasksets for testing, 'loggingMonitor.py' is a \nMonitor\n for testing, which writes to logs/monitor.log)\n\n\nfrom example import Hey0TaskSet\nfrom monitors.loggingMonitor import LoggingMonitor\nfrom distributor import Distributor\n\n\n\nDefining a monitor and tasksets for the execution is left to the user.\n\n\nInitialize modules:\n\n\nt = Hey0TaskSet()\nlm = LoggingMonitor()\ndist = Distributor()\n\n\n\nNow the distributor is running.\n\n\nAdding a job\n is possible via the add_jobs(taskset, monitor) function: \n\n\ndist.add_job(t,lm)\n\n\n\nThis will spawn machines acording to the current max_machine value.\n\n\nNote: You can repeat the above command to queue multiple jobs whenever you please.\n\n\nTo view a list of detached qemu instances \n\n\nsudo screen -ls\n\n\n\nTo kill a detached screen type:\n\n\nsudo screen -X -S <name\\_of\\_screen> kill\n\n\n\nThe log files of the genode instances are also saved in the log/ directory.\n\n\nAdditionally, you can adjust the number of spawned machines, also while the distributor is running. See the distributor functions for more information. \n\n\nDistributor functions\n\n\nSetting max machines to a value between 1 and 42. You can change this anytime as this only affects the maximum total number of spawned machines. If machines are active, the number will be adapted accordingly. Closing machines will still finish their current taskset before shutting down.\n\n\n    set_max_machine_value(numMachines)\n\n\n\nFunction to check if the distributor is busy or not. \n\n\n    get_distributor_state()\n\n\n\nReturn current maximum value of possible active machines\n\n\n    get_max_machine_value()\n\n\n\nCreating a new job and adding it to a list of jobs to be worked on.\nThe function is instantiating a new object of type TaskSetQueue which is then appended to the list of jobs to be processed.\n\n\n    add_job(taskset, monitor, *session_parameters)\n\n\n\nA job always consists of Taskset t and a Monitor, the session_parameters are optional. Inside the method a TaskSetQueue will hold the iterator which is returned by t.variants()\n\n\nKill all machines that are currently running \n\n\n    kill_all_machines()\n\n\n\nThe Machine class\n\n\nThe 'machine.py' implements a class which extends threading.Thread.\n\n\nAn instance of Machine is taking care of spawning a host, creating a session which connects to the spawned host and acquiring tasksets while there still is work to be done.",
            "title": "Distributor"
        },
        {
            "location": "/distributor/#distributor",
            "text": "Distributor is the main class/entity that controls and distributes host sessions to manage tasksets. Upon startup, the distributor will have a preset value of one host session that it will be able to spawn. The user is permitted to change this number at any time up to a hardcoded limit of forty one. Machines set to be closed will finish their assigned taskset before being shut down. The distributor is mainly used for gathering large-scale data about autonomous system schedulability-tasks, which can be used for data mining and analysis.",
            "title": "Distributor"
        },
        {
            "location": "/distributor/#set-up-and-configuration",
            "text": "Clone the client-tools repository and initialize the submodules and place a working  image.elf  file inside the client-tools directory.  With Vagrant  A  vagrant  script is provided in the client-tools repository, which will set up the appropriate development environment and prepare it for use without any manual installation or configuration.  (Executing the distributor inside a vagrant machine leads to an unknown error, which stops the execution at some point after about ten to thirty hours. As the vagrant machine serves only as a test and development environment, this is not a critical issue and will not be further investigated, as mentioned in the according  issue )  Manual Setup  Install Python 3.5 and pip3  sudo apt-get install python3.5 -qq\nsudo apt-get  install python3-pip -qq  Install the requirements for the taskgen module  sudo pip3 install -r client-tools/taskgen/requirements.txt  Install bridge functionality for networking:  sudo apt-get install bridge-utils -qq  Download DHCP service and move provided configuration file.   sudo apt-get install isc-dhcp-server -qq\nsudo cp dhcpd.conf /etc/dhcp/  Set up the bridge and assign an IP address (consult the dhcp.conf file for more information on IP ranges)  sudo brctl addbr br0\nsudo ip addr add 10.200.40.1/21 dev br0  Adjust /etc/network/interfaces file with preliminary networking information  sudo sh -c 'echo \"auto br0\\niface br0 inet dhcp\\nbridge_ports eth0\\nbridge_stp off\\nbridge_maxwait 0\\nbridge_fd 0\\n\" >> /etc/network/interfaces'  Install qemu and screen for spawning host sessions from the distributor and for easy visualization of spawned sessions.   sudo apt-get install qemu -qq\nsudo apt-get install screen -qq  Start the dhcp service  sudo systemctl start isc-dhcp-server  The machine should now be ready for use.",
            "title": "Set up and Configuration"
        },
        {
            "location": "/distributor/#using-the-distributor",
            "text": "The following is an example execution to provide better understanding.  Open up the interactive python shell  in the directory 'distributor_service' by typing (You can also create and execute this in a script)  sudo python3  Add appropriate imports:    ('example.py' holds some tasksets for testing, 'loggingMonitor.py' is a  Monitor  for testing, which writes to logs/monitor.log)  from example import Hey0TaskSet\nfrom monitors.loggingMonitor import LoggingMonitor\nfrom distributor import Distributor  Defining a monitor and tasksets for the execution is left to the user.  Initialize modules:  t = Hey0TaskSet()\nlm = LoggingMonitor()\ndist = Distributor()  Now the distributor is running.  Adding a job  is possible via the add_jobs(taskset, monitor) function:   dist.add_job(t,lm)  This will spawn machines acording to the current max_machine value.  Note: You can repeat the above command to queue multiple jobs whenever you please.  To view a list of detached qemu instances   sudo screen -ls  To kill a detached screen type:  sudo screen -X -S <name\\_of\\_screen> kill  The log files of the genode instances are also saved in the log/ directory.  Additionally, you can adjust the number of spawned machines, also while the distributor is running. See the distributor functions for more information.",
            "title": "Using the Distributor"
        },
        {
            "location": "/distributor/#distributor-functions",
            "text": "Setting max machines to a value between 1 and 42. You can change this anytime as this only affects the maximum total number of spawned machines. If machines are active, the number will be adapted accordingly. Closing machines will still finish their current taskset before shutting down.      set_max_machine_value(numMachines)  Function to check if the distributor is busy or not.       get_distributor_state()  Return current maximum value of possible active machines      get_max_machine_value()  Creating a new job and adding it to a list of jobs to be worked on.\nThe function is instantiating a new object of type TaskSetQueue which is then appended to the list of jobs to be processed.      add_job(taskset, monitor, *session_parameters)  A job always consists of Taskset t and a Monitor, the session_parameters are optional. Inside the method a TaskSetQueue will hold the iterator which is returned by t.variants()  Kill all machines that are currently running       kill_all_machines()",
            "title": "Distributor functions"
        },
        {
            "location": "/distributor/#the-machine-class",
            "text": "The 'machine.py' implements a class which extends threading.Thread.  An instance of Machine is taking care of spawning a host, creating a session which connects to the spawned host and acquiring tasksets while there still is work to be done.",
            "title": "The Machine class"
        },
        {
            "location": "/genode/",
            "text": "Genode & Fiasco Update\n\n\nThis section covers the updates for Genode and Fiasco.OC. \n\n\nAgenda\n\n\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+\n\n\n\n\n\n +\n\n\n\n\n\n\n\nSetup\n\n\nThe default setup listed below is based on Genode 16.08 and foc r67.\n\nTo use the new versions Genode 18.02 and foc r78 please take a look at \"Structure of directories\".\n\n\nIf you like to use a VM for this project,\n\nplease follow the steps on the \nArgOS-research website\n.\n\n\nIf you like to use your native machine,\n\njust clone https://github.com/argos-research/operating-system.git branch master\n\nand execute ./setup.sh .\n\nThis will build the project \"dom0-HW\" on platform \"focnados_panda\" by default.\n\nPlease adjust the MAKEFILE to your needs.\n\n\nStructure of directories\n\n\nGenode 18.02 and foc r78:\n\nhttps://github.com/malsami/genode\n\nbranch 18.02_r78\n\n\nGenode 18.02 and focnados r78:\n\nhttps://github.com/malsami/genode\n\nbranch focnados_18.02_r78\n\n\nCheckpoint Restore for Genode 18.02 and focnados r78:\n\nhttps://github.com/argos-research/genode-CheckpointRestore-SharedMemory\n\nbranch fixing_restore-AR-18.02",
            "title": "Genode"
        },
        {
            "location": "/genode/#genode-fiasco-update",
            "text": "This section covers the updates for Genode and Fiasco.OC.",
            "title": "Genode & Fiasco Update"
        },
        {
            "location": "/genode/#agenda",
            "text": "+    +",
            "title": "Agenda"
        },
        {
            "location": "/genode/#setup",
            "text": "The default setup listed below is based on Genode 16.08 and foc r67. \nTo use the new versions Genode 18.02 and foc r78 please take a look at \"Structure of directories\".  If you like to use a VM for this project, \nplease follow the steps on the  ArgOS-research website .  If you like to use your native machine, \njust clone https://github.com/argos-research/operating-system.git branch master \nand execute ./setup.sh . \nThis will build the project \"dom0-HW\" on platform \"focnados_panda\" by default. \nPlease adjust the MAKEFILE to your needs.",
            "title": "Setup"
        },
        {
            "location": "/genode/#structure-of-directories",
            "text": "Genode 18.02 and foc r78: \nhttps://github.com/malsami/genode \nbranch 18.02_r78  Genode 18.02 and focnados r78: \nhttps://github.com/malsami/genode \nbranch focnados_18.02_r78  Checkpoint Restore for Genode 18.02 and focnados r78: \nhttps://github.com/argos-research/genode-CheckpointRestore-SharedMemory \nbranch fixing_restore-AR-18.02",
            "title": "Structure of directories"
        },
        {
            "location": "/machine_learning/",
            "text": "Machine Learning\n\n\nMachine Learning is a useful tool for \npattern matching\n and curve fitting to make predictions based on data itself. Given the recent breakthroughs and ease of use, it is worthwhile to try to analyze our problem in the lens of machine learning and analyze how our analysis changes. Since we are using real-time systems, we must also analyze the efficiency and cost of the algorithms and understand the tradeoffs among different techniques. Certain algorithms may be more suitable for the offline training phase while others on the online training phase. All of these are factors that will be considered when analyzing the models. \n\n\nThe models will be evaluated loosely on their time of execution but more on their classification ability. As with all machine learning tasks, the goal is for high precision and high recall. This ensures that our models can not only correctly classify data to its appropriate labels, but that it is able to do so without overfitting. \n\n\nWe are pursuing both routes with \nDeep Learning\n and \nShallow_Learning\n to compare the approaches. Although deep learning models are more flexible and advanced than its shallow learning counterparts, it is important to analyze both to see the strenghts of both approaches. Since resources and time of execution are a factor in the online phase, it is important to see whether a heavyweight network is worth the cost. Furthermore, this analysis will provide insight into the underlying patterns and general structure of the data. This will pave the way for further research to be done in both schedulability and data analysis. \n\n\nHowever, to get a more complete analysis, it is important to investigate as many viable choices as we can get. Furthermore, different data-mining",
            "title": "Machine learning"
        },
        {
            "location": "/monitor/",
            "text": "Monitor\n\n\nThis section is supposed to provide insight on the monitor component and how it is intended to be used. The monitor has to be provided alongside the taskset component to the \nadd_jobs()\n function of the distributor. The monitors functions are called in \nrun()\n of the \nmachine.py\n.\n\n\nA monitor has to implement the \nAbstractMonitor\n in the distributor_service module which defines the following abstract methods:\n\n\n__taskset_event__(taskset, event)\n\n\nThis function is called when the \nsession.run()\n as soon as new information about the taskset is returned from Genode.\n\n\n__taskset_start__(taskset)\n\n\nThis function is called when a new taskset has benn started by calling the \nsession.start()\n function.\n\n\n__taskset_stop__(taskset)\n\n\nThis function is called when a new taskset has benn started by calling the \nsession.stop()\n function. If this function is called the monitor regards the taskset as completed and all information, which could be gained is available. \n\n\n__taskset_finish__(self, taskset)\n\n\nIn general the monitor functions always hold a reference to the taskset the function was called with, so it has access to all information saved in the obect defined by the \ntask.py\n.",
            "title": "Monitor"
        },
        {
            "location": "/monitor/#monitor",
            "text": "This section is supposed to provide insight on the monitor component and how it is intended to be used. The monitor has to be provided alongside the taskset component to the  add_jobs()  function of the distributor. The monitors functions are called in  run()  of the  machine.py .  A monitor has to implement the  AbstractMonitor  in the distributor_service module which defines the following abstract methods:  __taskset_event__(taskset, event)  This function is called when the  session.run()  as soon as new information about the taskset is returned from Genode.  __taskset_start__(taskset)  This function is called when a new taskset has benn started by calling the  session.start()  function.  __taskset_stop__(taskset)  This function is called when a new taskset has benn started by calling the  session.stop()  function. If this function is called the monitor regards the taskset as completed and all information, which could be gained is available.   __taskset_finish__(self, taskset)  In general the monitor functions always hold a reference to the taskset the function was called with, so it has access to all information saved in the obect defined by the  task.py .",
            "title": "Monitor"
        },
        {
            "location": "/reqAnalysis/",
            "text": "Requirements Analysis for MaLSAMi (Machine Learning based Schedulability Analysis for inter device Migration of software based components during Runtime)\n\n\nWhat we want to do\n\n\non multi ecu system: \n    - tasks are running on multiple electronic computing units (ECU).\n    - on each ECU checkpoints of the current state_/progress of the running tasks are created periodically\n    - at some point in time a ECU might fail, then, based on information about the running tasks, a decision for migration of the tasks on the failed ECU has to be made.\n    - for this decision some kind of schedulability analysis is necessary.\n    - after a decision is made, the checkpoint has to be restored on another ECU and all tasks should continue to run\n\n\nCreating checkpoints of running tasks could include the memory, the assigned capabilities or the registers.\nAfter an initial full checkpoint an incremental approach to saving changes is also a posibility.\n\n\nThe migration of a task by restoring a checkpoint to another ECU could happen either directly to another ECU or by collecting all the checkpoints of all the ECUs to a different machine and redistributing them to a chosen target ECU when necessary.\nAnother variant of checkpointing would be to create an initial full checkpoint followed by smaller change-based incremental checkpoints. These incremental checkpoints might be integrated into the full checkpoint on the same ECU before sending it to another machine, or every checkpoint is sent right after creation.\nA possible use-case for checkpoints, which is not being looked into is the restart of failed tasks at its last known state on the same machine.\n\n\nThe decision where a task is migrated to is mainly based on the general information about the task but it could also be a posibillity to include the information gained through the checkpoints to find the best solution.\nLearning (of any kind) can be performed in three general categories: \n-offline on a different ECU or computer for exactly the purpose of analysing the data and performing the migration planning.\n-online on very strong ECUs which are performing tasks and also the data analysis and decision making necessary for migration\n-online on normal ECUs (embedded boards) which are performing tasks and also the data analysis and decision making necessary for migration\n\n\nWhat we have\n\n\nHardware\n\n\n3 Workstations:\n-   titan V\n\n\n\n\n\n\n3x gtx1080ti\n\n\n\n\n\n\n2x tesla k20c\n    quadro k4200\n\n\n\n\n\n\nData\n\n\nCheckpointing currently includes only the information in the memory. Checkpointing the capabilities or the registers is not possible yet.\n\n\nNo data yet, we will have to generate it using the implemented distributor.\n\n\nWhich data can be aquired from the distributor is dependent on the defined monitor, but the most information that can be gained are the parameters of each taskset, which were handed over to the genode operating system, and also the start and stop times of each job of each task and also the exit value.\n\n\nAvailable Software\n\n\nPython 3.5.2\nPytorch va\nCuda v\nQemu \nGenode\ncxxnet\nTheano\nTorch7\n\n\nWhat we can do\n\n\nMultiple frameworks for deep learning and parallel programming. \n\n\nPytorch allows easy high level implementation of deep neural networks along with GPU accelerated computation. This will be especially useful in speeding pu computation of deep neural networks. These GPUs will allow the networks to train on more data in less time. This feature will be especially useful when during the offline training phase, as this is where the GPUs are available.  \n\n\nThere are numerous other frameworks that can be used as well. It is difficult to say which is optimal and usually they all are highly capable. Pytorch is good because of its ease in utilizing GPU architecture with neural networks. However, there are numerous other libraries that are specialized to the type of network or learning technique we are using. Cuda-convnet is another project that utilizes C++ Cuda implementatoin of neural networks. If we observe that the neural networks are performing well and we want to optimize, we can then pursue these libraries. \n\n\nShallow Learning techniques are much simpler than Deep Learning techniques and do not always require very sophisticated libraries. Furthermore, whether or not the learning phase can or should be parallelized can be decided later. \n\n\nGiven the resources, we have for the offline training phase, we will attempt to parallelize and optimize the algorithms wherever possible. \n\n\nAfter these rudimentary shallow and deep learning techniques are applied. We can look into reinforcement learning, a newer machine learning approach that is especially used for autonomous driving. The main difference between reinforcement learning and regular supervised/unsupervised machine learning is how an agent decides which actions to take based on the environment. We are currently mostly concerned with schedulablitity analysis, which will be learned based on the data itself. However, further analysis of the acquired data and the patterns analyzed may bring some interest into this type of approach. \n\n\nThe ECUs allow us to use multiple forms of information which will be helpful for machine learning training such as lidar, radars, etc. \n\n\nCheckpointing\n\n\nCurrent state and snapshot of resources could be used for restarting in case of ECU failure or other problems. Learning can be done by continually monitoring these states and then using them as inputs into the machine learning models. \n\n\nDeep Learning would react better to this as it would be able to properly account for different kinds of input better than shallow learning techniques. Furthermore, the more sophisticated/complicated the data, the more likely that deep learning will perform better.  \n\n\nReinforcement Learning would be helpful in the checkpointing as it will be able to decide whether or not it wants to add a checkpoint based on its environment and available states. Obviously, if the probability of an ecu failing in a particular environment is high, it would be a good idea to add a checkpoint. These are areas that reinforcement learning would be better able to handle rather than regular shallow/deep learning. \n\n\nLearning\n\n\nWhen it comes to learning techniques, there are many options. MaLSAMi is going to look into Deep and Shallow Learning based data analysis and decision making.\n\n\nDeep Learning\n\n\nDeep Learning works best when there is a lot of data to sample from. These algorithms will be mostly utilized in the 'offline' phase of the learning. Deep Learning has a variety of different neural network models such as Generative Adversarial Networks (GAN), Spiking Neural Networks (SNN), Feed Forward Networks (FNN), Recurrent Neural Networks (RNN) and Convolutional  CNN.  These networks are specializied for specific types of data mining and analysis and are never a 'one fits all' model. Therefore, we plan to analyze several of these different models. Each of the networks listed below are catered to a certain kind of problem, but they are not too specialized to be unadaptable. \n\n\nTesting\n\n\nFor both approaches, we will use the standard metrics of testing for shallow and deep learning. This will include shuffling of training splits, cross validation, and in depth classification reports measuring the accuracy, precision, and recall to understand exactly what is happenign with the algorithms. \n\n\nThe optimal scenario would be to have enough data for the network to train completely on one set and only touch the test set once for everytime it is testing. However, given how much viable data that is available, this may not be what actually happens. \n\n\nFor the networks, it is very important that we do not fall prey to overfitting the test data. Hopefully, with a lot of data from the distributor we can avoid this problem.",
            "title": "reqAnalysis"
        },
        {
            "location": "/reqAnalysis/#requirements-analysis-for-malsami-machine-learning-based-schedulability-analysis-for-inter-device-migration-of-software-based-components-during-runtime",
            "text": "",
            "title": "Requirements Analysis for MaLSAMi (Machine Learning based Schedulability Analysis for inter device Migration of software based components during Runtime)"
        },
        {
            "location": "/reqAnalysis/#what-we-want-to-do",
            "text": "on multi ecu system: \n    - tasks are running on multiple electronic computing units (ECU).\n    - on each ECU checkpoints of the current state_/progress of the running tasks are created periodically\n    - at some point in time a ECU might fail, then, based on information about the running tasks, a decision for migration of the tasks on the failed ECU has to be made.\n    - for this decision some kind of schedulability analysis is necessary.\n    - after a decision is made, the checkpoint has to be restored on another ECU and all tasks should continue to run  Creating checkpoints of running tasks could include the memory, the assigned capabilities or the registers.\nAfter an initial full checkpoint an incremental approach to saving changes is also a posibility.  The migration of a task by restoring a checkpoint to another ECU could happen either directly to another ECU or by collecting all the checkpoints of all the ECUs to a different machine and redistributing them to a chosen target ECU when necessary.\nAnother variant of checkpointing would be to create an initial full checkpoint followed by smaller change-based incremental checkpoints. These incremental checkpoints might be integrated into the full checkpoint on the same ECU before sending it to another machine, or every checkpoint is sent right after creation.\nA possible use-case for checkpoints, which is not being looked into is the restart of failed tasks at its last known state on the same machine.  The decision where a task is migrated to is mainly based on the general information about the task but it could also be a posibillity to include the information gained through the checkpoints to find the best solution.\nLearning (of any kind) can be performed in three general categories: \n-offline on a different ECU or computer for exactly the purpose of analysing the data and performing the migration planning.\n-online on very strong ECUs which are performing tasks and also the data analysis and decision making necessary for migration\n-online on normal ECUs (embedded boards) which are performing tasks and also the data analysis and decision making necessary for migration",
            "title": "What we want to do"
        },
        {
            "location": "/reqAnalysis/#what-we-have",
            "text": "Hardware  3 Workstations:\n-   titan V    3x gtx1080ti    2x tesla k20c\n    quadro k4200    Data  Checkpointing currently includes only the information in the memory. Checkpointing the capabilities or the registers is not possible yet.  No data yet, we will have to generate it using the implemented distributor.  Which data can be aquired from the distributor is dependent on the defined monitor, but the most information that can be gained are the parameters of each taskset, which were handed over to the genode operating system, and also the start and stop times of each job of each task and also the exit value.  Available Software  Python 3.5.2\nPytorch va\nCuda v\nQemu \nGenode\ncxxnet\nTheano\nTorch7",
            "title": "What we have"
        },
        {
            "location": "/reqAnalysis/#what-we-can-do",
            "text": "Multiple frameworks for deep learning and parallel programming.   Pytorch allows easy high level implementation of deep neural networks along with GPU accelerated computation. This will be especially useful in speeding pu computation of deep neural networks. These GPUs will allow the networks to train on more data in less time. This feature will be especially useful when during the offline training phase, as this is where the GPUs are available.    There are numerous other frameworks that can be used as well. It is difficult to say which is optimal and usually they all are highly capable. Pytorch is good because of its ease in utilizing GPU architecture with neural networks. However, there are numerous other libraries that are specialized to the type of network or learning technique we are using. Cuda-convnet is another project that utilizes C++ Cuda implementatoin of neural networks. If we observe that the neural networks are performing well and we want to optimize, we can then pursue these libraries.   Shallow Learning techniques are much simpler than Deep Learning techniques and do not always require very sophisticated libraries. Furthermore, whether or not the learning phase can or should be parallelized can be decided later.   Given the resources, we have for the offline training phase, we will attempt to parallelize and optimize the algorithms wherever possible.   After these rudimentary shallow and deep learning techniques are applied. We can look into reinforcement learning, a newer machine learning approach that is especially used for autonomous driving. The main difference between reinforcement learning and regular supervised/unsupervised machine learning is how an agent decides which actions to take based on the environment. We are currently mostly concerned with schedulablitity analysis, which will be learned based on the data itself. However, further analysis of the acquired data and the patterns analyzed may bring some interest into this type of approach.   The ECUs allow us to use multiple forms of information which will be helpful for machine learning training such as lidar, radars, etc.   Checkpointing  Current state and snapshot of resources could be used for restarting in case of ECU failure or other problems. Learning can be done by continually monitoring these states and then using them as inputs into the machine learning models.   Deep Learning would react better to this as it would be able to properly account for different kinds of input better than shallow learning techniques. Furthermore, the more sophisticated/complicated the data, the more likely that deep learning will perform better.    Reinforcement Learning would be helpful in the checkpointing as it will be able to decide whether or not it wants to add a checkpoint based on its environment and available states. Obviously, if the probability of an ecu failing in a particular environment is high, it would be a good idea to add a checkpoint. These are areas that reinforcement learning would be better able to handle rather than regular shallow/deep learning.   Learning  When it comes to learning techniques, there are many options. MaLSAMi is going to look into Deep and Shallow Learning based data analysis and decision making.  Deep Learning  Deep Learning works best when there is a lot of data to sample from. These algorithms will be mostly utilized in the 'offline' phase of the learning. Deep Learning has a variety of different neural network models such as Generative Adversarial Networks (GAN), Spiking Neural Networks (SNN), Feed Forward Networks (FNN), Recurrent Neural Networks (RNN) and Convolutional  CNN.  These networks are specializied for specific types of data mining and analysis and are never a 'one fits all' model. Therefore, we plan to analyze several of these different models. Each of the networks listed below are catered to a certain kind of problem, but they are not too specialized to be unadaptable.   Testing  For both approaches, we will use the standard metrics of testing for shallow and deep learning. This will include shuffling of training splits, cross validation, and in depth classification reports measuring the accuracy, precision, and recall to understand exactly what is happenign with the algorithms.   The optimal scenario would be to have enough data for the network to train completely on one set and only touch the test set once for everytime it is testing. However, given how much viable data that is available, this may not be what actually happens.   For the networks, it is very important that we do not fall prey to overfitting the test data. Hopefully, with a lot of data from the distributor we can avoid this problem.",
            "title": "What we can do"
        },
        {
            "location": "/schedulabilityAnalysis/",
            "text": "Schedulability Analysis \n\n\nOn real-time systems, tasks will be executed and processed on multiple different ECUs. These ECUs are responsible for various distributed tasks whose analysis is important for migration planning in the probable event of system failure. \n\n\nOn multi-ecu systems, the ECUs hold information about the task such as the start/end time. In the event of an ECU failure, it must have a prevention/recovery method in which it can migrate unfinished tasks to other ECUs  that it has not been able to complete. The aim of the schedulability analysis is to 'learn' and 'analyze' from past events and previous scenarios for better damage control. \n\n\nCreating checkpoints of running tasks could include the memory, the assigned capabilities or the registers.\nAfter an initial full checkpoint an incremental approach to saving changes is also a posibility.\n\n\nThe migration of a task by restoring a checkpoint to another ECU could happen either directly to another ECU or by collecting all the checkpoints of all the ECUs to a different machine and redistributing them to a chosen target ECU when necessary.\nAnother variant of checkpointing would be to create an initial full checkpoint followed by smaller change-based incremental checkpoints. These incremental checkpoints might be integrated into the full checkpoint on the same ECU before sending it to another machine, or every checkpoint is sent right after creation.\nA possible use-case for checkpoints, which is not being looked into is the restart of failed tasks at its last known state on the same machine.\n\n\nThe decision where a task is migrated to is mainly based on the general information about the task but it could also be a posibillity to include the information gained through the checkpoints to find the best solution.\n\n\nLearning (of any kind) can be performed in three general categories: \n-offline on a different ECU or computer for exactly the purpose of analysing the data and performing the migration planning.\n-online on very strong ECUs which are performing tasks and also the data analysis and decision making necessary for migration\n-online on normal ECUs (embedded boards) which are performing tasks and also the data analysis and decision making necessary for migration\n\n\nThe advantage of offline learning is that we are able to utilize virtually all of our resources and compute time to test multiple algorithms to fit the data. The disadvantage with this is that we will be dealing with a static datasets. Althought this does not imply that the dataset is erroneous, it is not akin to real time data that will happen at the online phase. \n\n\nFurthremore, heavy computation and time used to fit a static datasets very likely leads to overfitting. Even if appropriate measures are made, it is possible that the online data could be different from that of the dataset used. \n\n\nAnalogously, the online training is beneficial and detrimental for the opposite reasons. While online, we do not have as much time and resources as we do while offline. Especially in the situation that we are in now, we must process the data quickly. Therefore, we used the online training as more of a 'validation' stage in which we fine tune the models and hyperparameters. \n\n\nThe distributor is the module responsible for data generation that we will be used for the schedulability analysis. See the \ndistributor file\n for more information about the distributor. \n\n\nTo further analyze the methods we are using, view \nMachine Learning\n and the \nrequirement analysis",
            "title": "schedulabilityAnalysis"
        }
    ]
}